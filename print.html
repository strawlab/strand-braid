<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>User's Guide for Braid and Strand Camera</title>
        
        <meta name="robots" content="noindex" />
        
        


        <!-- Custom HTML head -->
        


        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="Low latency image processing and tracking">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        
        <link rel="icon" href="favicon.svg">
        
        
        <link rel="shortcut icon" href="favicon.png">
        
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        
        <link rel="stylesheet" href="css/print.css" media="print">
        

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        
        <link rel="stylesheet" href="fonts/fonts.css">
        

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="braid-and-strand-camera.html">Braid and Strand Camera</a></li><li class="chapter-item expanded "><a href="hardware-selection.html"><strong aria-hidden="true">1.</strong> Hardware selection</a></li><li class="chapter-item expanded "><a href="installation.html"><strong aria-hidden="true">2.</strong> Installation</a></li><li class="chapter-item expanded "><a href="braid_configuration_and_launching.html"><strong aria-hidden="true">3.</strong> Configuring and Launching Braid</a></li><li class="chapter-item expanded "><a href="braidz-files.html"><strong aria-hidden="true">4.</strong> BRAIDZ files and Analysis Scripts</a></li><li class="chapter-item expanded "><a href="braid_3d_tracking.html"><strong aria-hidden="true">5.</strong> Braid: 3D Tracking</a></li><li class="chapter-item expanded "><a href="parameters_for_object_detection_and_tracking.html"><strong aria-hidden="true">6.</strong> Parameters for Object Detection and Tracking</a></li><li class="chapter-item expanded "><a href="braid_calibration.html"><strong aria-hidden="true">7.</strong> Braid: 3D Calibration</a></li><li class="chapter-item expanded "><a href="braid_remote_cameras.html"><strong aria-hidden="true">8.</strong> Braid: Remote cameras</a></li><li class="chapter-item expanded "><a href="scripting-with-python.html"><strong aria-hidden="true">9.</strong> Scripting with Python</a></li><li class="chapter-item expanded "><a href="processing-saved-videos.html"><strong aria-hidden="true">10.</strong> Processing saved videos</a></li><li class="chapter-item expanded "><a href="fmf_format.html"><strong aria-hidden="true">11.</strong> Fly Movie Format</a></li><li class="chapter-item expanded "><a href="troubleshooting.html"><strong aria-hidden="true">12.</strong> Troubleshooting</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        
                    </div>

                    <h1 class="menu-title">User's Guide for Braid and Strand Camera</h1>

                    <div class="right-buttons">
                        
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                        
                        <a href="https://github.com/strawlab/strand-braid/tree/main/strand-braid-user/users-guide" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                        
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1><a class="header" href="#braid-and-strand-camera" id="braid-and-strand-camera">Braid and Strand Camera</a></h1>
<p>This is the User's Guide for <a href="https://strawlab.org/braid/">Braid</a> and <a href="https://strawlab.org/strand-cam/">Strand
Camera</a>.</p>
<p>Braid and Strand Camera are free and open source. You can find the source code
on <a href="https://github.com/strawlab/strand-braid">GitHub</a>. Issues and feature
requests can be posted on the <a href="https://github.com/strawlab/strand-braid/issues">GitHub issue
tracker</a>.</p>
<h3><a class="header" href="#about-this-book" id="about-this-book">About this book</a></h3>
<p>The source code for this documentation is at
<a href="https://github.com/strawlab/strand-braid/tree/main/strand-braid-user/users-guide">github.com/strawlab/strand-braid/tree/main/strand-braid-user/users-guide</a>.
This book is made with <a href="https://rust-lang.github.io/mdBook/">mdBook</a>.</p>
<h1><a class="header" href="#hardware-selection" id="hardware-selection">Hardware selection</a></h1>
<h2><a class="header" href="#pc-requirements" id="pc-requirements">PC requirements</a></h2>
<ul>
<li>Supports Ubuntu 20.04 amd64 operating system. This is currently our only
supported platform.</li>
<li>Fast CPU. Currently an Intel CPU is recommended due to the use of the Intel
Integrated Performance Primitives Library.</li>
<li>Memory usage is not expected to be particularly high, because processing
occurs in realtime.</li>
<li>Sufficient and fast interfaces to cameras. If your cameras are USB3 or Gigabit
ethernet, your computer needs to support enough bandwidth.</li>
<li>Disk space and speed. For realtime tracking, the tracking data is only modest
in size and so no particularly high performance requirements exist. With
Nvidia hardware that supports NVENC hardware-accelerated encoding (see below),
compressed, H.264 encoded video can be saved to MP4 files with also only
modest CPU and disk requirements are present. For streaming uncompressed, raw
video to disk (with MP4 or the FMF format), very fast disks and lots of disk
space are required.</li>
</ul>
<h3><a class="header" href="#hardware-accelerated-video-encoding-using-nvidia-video-cards" id="hardware-accelerated-video-encoding-using-nvidia-video-cards">Hardware-accelerated video encoding using nvidia video cards</a></h3>
<p>NVIDIA video encoding hardware is optionally used to encode H.264 videos in the
MP4 format. This is very nice because it takes almost no CPU and full framerate
videos can be recorded from your cameras during live tracking with little or no
loss of performance. This depends on NVIDIA's library called NVENC. Please see
NVIDIA's site for <a href="https://developer.nvidia.com/video-encode-and-decode-gpu-support-matrix-new">supported
hardware</a>.
Note in particular the limit of three encode sessions with the consumer
(GeForce) hardware that does not exist on many of their professional (Quadro)
cards.</p>
<h2><a class="header" href="#camera-requirements" id="camera-requirements">Camera requirements</a></h2>
<p>Currently, Basler cameras using the Pylon API are the only supported cameras. We
plan to support cameras from Allied Vision using the Vimba API in late 2021 or 2022.</p>
<h3><a class="header" href="#basler-cameras" id="basler-cameras">Basler cameras</a></h3>
<p>Due to the use of the Pylon API, any camera which can be used in the Pylon
Viewer can be used in principle. In practice, we regularly test with the
following cameras:</p>
<ul>
<li>Basler a2A1920-160umPRO</li>
<li>Basler a2A1920-160umBAS</li>
<li>Basler acA1300-200um</li>
<li>Basler acA640-120gm</li>
</ul>
<h3><a class="header" href="#allied-vision-cameras-planned-for-late-2021-or-2022" id="allied-vision-cameras-planned-for-late-2021-or-2022">Allied Vision cameras (Planned for late 2021 or 2022)</a></h3>
<p>Due to the use of the Vimba API, any camera which can be used in the Vimba
Viewer can be used in principle. In practice, we intend to use the following
cameras:</p>
<ul>
<li>Allied Vision Alvium 1800 U-240m</li>
</ul>
<h1><a class="header" href="#installation" id="installation">Installation</a></h1>
<h2><a class="header" href="#software-installation" id="software-installation">Software installation</a></h2>
<p>Download releases from <a href="https://github.com/strawlab/strand-braid/releases">our releases
page</a>.</p>
<p>Choosing the correct installer for your operating system. We build releases of
Strand Camera and Braid for recent Ubuntu Linux Long Term Support (LTS)
releases. Each Ubuntu release has a version number (e.g. &quot;24.04&quot;) and a code
name (e.g. &quot;Noble Numbat&quot;). The installers at the releases page hosted on Github
are available in the &quot;Assets&quot; section with names like:
<code>strand-braid-ubuntu-&lt;UBUNTU_VERSION&gt;-&lt;STRAND_BRAID_VERSION&gt;.zip</code>. Here
<code>UBUNTU_VERSION</code> could be something like <code>2404</code> which would correspond to Ubuntu
24.04. Download and expand this <code>.zip</code> file. It contains a <code>README.txt</code> file
with further instructions and a <code>.deb</code> file which can be installed by the Ubuntu
operating system by double-clicking in the file manager.</p>
<!--

Note: the source for the README.txt files included in the installler .zip are
in _packaging/ubuntu-2404-installer-zip-readme.txt

-->
<h2><a class="header" href="#hardware-installation" id="hardware-installation">Hardware installation</a></h2>
<h3><a class="header" href="#cameras" id="cameras">Cameras</a></h3>
<p>Currently Basler cameras are best supported. We use Basler's Pylon library to
access the cameras.</p>
<p>Allied Vision Cameras using the Vimba X library is planned for Strand Camera and
Braid version 0.12.</p>
<h3><a class="header" href="#trigger-box" id="trigger-box">Trigger box</a></h3>
<p>Braid uses the <a href="https://github.com/strawlab/triggerbox">Straw Lab Triggerbox</a>
hardware to synchronize the cameras. This is based on an Arduino
microcontroller.</p>
<p>On Ubuntu, it is important to add your user to the <code>dialout</code> group so that you
can access the Triggerbox. Do so like this:</p>
<pre><code class="language-ignore">sudo adduser &lt;username&gt; dialout
</code></pre>
<h3><a class="header" href="#trigger-cables" id="trigger-cables">Trigger cables</a></h3>
<p>TODO: write this and describe how to check everything is working.</p>
<h1><a class="header" href="#braid-configuration-and-launching" id="braid-configuration-and-launching">Braid Configuration and Launching</a></h1>
<h2><a class="header" href="#how-to-launch-braid" id="how-to-launch-braid">How to launch Braid</a></h2>
<p>The central runtime of Braid, the <code>braid-run</code> executable, is launched from the
command line like so:</p>
<pre><code class="language-ignore">braid run braid-config.toml
</code></pre>
<p>The <code>braid-config.toml</code> is the path of a Braid TOML configuration file.</p>
<h2><a class="header" href="#braid-toml-configuration-files" id="braid-toml-configuration-files">Braid TOML configuration files</a></h2>
<p>The Braid configuration file, in the <a href="https://toml.io/">TOML format</a>, specifies
how Braid and multiple Strand Camera instances are launched. Any options not
specified result in default values being used. The defaults should be reasonable
and secure, allowing minimal configurations describing only specific aspects of
a particular setup.</p>
<p>The reference documentation for the <code>BraidConfig</code> type, which is automatically
deserialized from a <code>.toml</code> file:
<a href="https://strawlab.org/strand-braid-api-docs/latest/braid_config_data/struct.BraidConfig.html"><code>braid_config_data::BraidConfig</code></a>.</p>
<p>Here is a minimal configuration for a 3 camera Braid setup:</p>
<pre><code class="language-toml"># Simple example of a Braid configuration TOML file

# The reference documentation for this file is
# https://strawlab.org/strand-braid-api-docs/latest/braid_config_data/struct.BraidConfig.html

# This configuration uses 3 emulated Basler cameras. Set the environment
# variable `PYLON_CAMEMU=3` to configure the Basler Pylon driver to emulate 3
# cameras. In normal usage, you would set your camera names here. There is one
# `[[cameras]]` section for each Strand Camera instance to be launched, and thus
# one such section for each camera.
[[cameras]]
# Each camera `name` is computed from its vendor and serial number.
name = &quot;Basler-0815-0000&quot;

[[cameras]]
name = &quot;Basler-0815-0001&quot;

[[cameras]]
name = &quot;Basler-0815-0002&quot;
</code></pre>
<h1><a class="header" href="#braidz-files" id="braidz-files"><code>.braidz</code> files</a></h1>
<p>A <code>.braidz</code> file contains the results of realtime tracking, the tracking
parameters, and so on.</p>
<h2><a class="header" href="#viewer" id="viewer">Viewer</a></h2>
<p>A viewer for <code>.braidz</code> files is at <a href="https://braidz.strawlab.org/">braidz.strawlab.org</a>.</p>
<h2><a class="header" href="#analysis-scripts" id="analysis-scripts">Analysis scripts</a></h2>
<p>Scripts to analyze your <code>.braidz</code> files can be found at <a href="https://github.com/strawlab/strand-braid/tree/main/strand-braid-user/analysis">github.com/strawlab/strand-braid/tree/main/strand-braid-user/analysis</a>.</p>
<h3><a class="header" href="#latency-analysis" id="latency-analysis">Latency Analysis</a></h3>
<p>To analyze the latency of your setup with Braid, you can use the Jupyter Notebook <code>braid-latency-analysis.ipynb</code>.</p>
<h3><a class="header" href="#content-analysis" id="content-analysis">Content analysis</a></h3>
<p>The Jupyter Notebook <code>braidz-contents.ipynb</code> can be used to view the Kalman estimates, the raw 2D detections, data on the association of cameras, and data on associations between 2D detection and 3D Tracking in your <code>.braidz</code> file.</p>
<h2><a class="header" href="#plotting" id="plotting">Plotting</a></h2>
<p>The following plots were made with the file
<a href="https://strawlab-cdn.com/assets/20201112_133722.braidz">20201112_133722.braidz</a>.
The scripts can be accessed at
<a href="https://github.com/strawlab/strand-braid/tree/main/strand-braid-user/analysis">github.com/strawlab/strand-braid/tree/main/strand-braid-user/analysis</a>.
A Jupyter Notebook to create all of these plots can be found in <code>braid-plotting.ipynb</code> in the same folder.</p>
<h3><a class="header" href="#braid-analysis-plot-data2d-timeseriespy" id="braid-analysis-plot-data2d-timeseriespy"><code>braid-analysis-plot-data2d-timeseries.py</code></a></h3>
<p><img src="images/braid-analysis-plot-data2d-timeseries.png" alt="images/braid-analysis-plot-data2d-timeseries.png" /></p>
<h3><a class="header" href="#braid-analysis-plot-kalman-estimates-timeseriespy" id="braid-analysis-plot-kalman-estimates-timeseriespy"><code>braid-analysis-plot-kalman-estimates-timeseries.py</code></a></h3>
<p><img src="images/braid-analysis-plot-kalman-estimates-timeseries.png" alt="images/braid-analysis-plot-kalman-estimates-timeseries.png" /></p>
<h3><a class="header" href="#braid-analysis-plot3dpy" id="braid-analysis-plot3dpy"><code>braid-analysis-plot3d.py</code></a></h3>
<p><img src="images/braid-analysis-plot3d.png" alt="images/braid-analysis-plot3d.png" /></p>
<h2><a class="header" href="#file-format" id="file-format">File Format</a></h2>
<p>A <code>.braidz</code> file is actually a ZIP file with specific contents. It can be
helpful to know about these specifics when problems arise.</p>
<h3><a class="header" href="#showing-the-contents-of-a-braidz-file" id="showing-the-contents-of-a-braidz-file">Showing the contents of a <code>.braidz</code> file</a></h3>
<p>You can show the filenames inside a .braidz file with
<code>unzip -l FILENAME.braidz</code>.</p>
<h3><a class="header" href="#extracting-a-braidz-file" id="extracting-a-braidz-file">Extracting a <code>.braidz</code> file</a></h3>
<p>You can extract a <code>.braidz</code> file to its contents with <code>unzip FILENAME.braidz</code>.</p>
<h3><a class="header" href="#creating-a-braidz-file" id="creating-a-braidz-file">Creating a <code>.braidz</code> file</a></h3>
<p>You can create a new <code>.braidz</code> file with:</p>
<pre><code class="language-ignore">cd BRAID_DIR
zip ../FILENAME.braidz *
</code></pre>
<p>Note, your <code>.braidz</code> file should look like this - with no directories other than
<code>images/</code>.</p>
<pre><code class="language-ignore">$ unzip -l 20191125_093257.braidz
Archive:  20191125_093257.braidz
zip-rs
  Length      Date    Time    Name
---------  ---------- -----   ----
       97  2019-11-25 09:33   README.md
      155  2019-11-25 09:33   braid_metadata.yml
        0  2019-11-25 09:33   images/
   308114  2019-11-25 09:33   images/Basler_22005677.png
   233516  2019-11-25 09:33   images/Basler_22139107.png
   283260  2019-11-25 09:33   images/Basler_22139109.png
   338040  2019-11-25 09:33   images/Basler_22139110.png
       78  2019-11-25 09:33   cam_info.csv.gz
     2469  2019-11-25 09:33   calibration.xml
      397  2019-11-25 09:33   textlog.csv.gz
   108136  2019-11-25 09:33   kalman_estimates.csv.gz
      192  2019-11-25 09:33   trigger_clock_info.csv.gz
       30  2019-11-25 09:33   experiment_info.csv.gz
     2966  2019-11-25 09:33   data_association.csv.gz
   138783  2019-11-25 09:33   data2d_distorted.csv.gz
---------                     -------
  1416233                     15 files
</code></pre>
<p>Note that the following is NOT a valid <code>.braidz</code> file because it has a leading
directory name for each entry.</p>
<pre><code class="language-ignore">$ unzip -l 20191119_114103.NOT-A-VALID-BRAIDZ
Archive:  20191119_114103.NOT-A-VALID-BRAIDZ
  Length      Date    Time    Name
---------  ---------- -----   ----
        0  2019-11-19 11:41   20191119_114103.braid/
       97  2019-11-19 11:41   20191119_114103.braid/README.md
      155  2019-11-19 11:41   20191119_114103.braid/braid_metadata.yml
        0  2019-11-19 11:41   20191119_114103.braid/images/
   320906  2019-11-19 11:41   20191119_114103.braid/images/Basler_22005677.png
   268847  2019-11-19 11:41   20191119_114103.braid/images/Basler_22139107.png
   308281  2019-11-19 11:41   20191119_114103.braid/images/Basler_22139109.png
   346232  2019-11-19 11:41   20191119_114103.braid/images/Basler_22139110.png
   225153  2019-11-19 11:41   20191119_114103.braid/images/Basler_40019416.png
       86  2019-11-19 11:41   20191119_114103.braid/cam_info.csv.gz
     2469  2019-11-19 11:41   20191119_114103.braid/calibration.xml
       10  2019-11-19 11:41   20191119_114103.braid/textlog.csv.gz
       10  2019-11-19 11:41   20191119_114103.braid/kalman_estimates.csv.gz
       10  2019-11-19 11:41   20191119_114103.braid/trigger_clock_info.csv.gz
       10  2019-11-19 11:41   20191119_114103.braid/experiment_info.csv.gz
       10  2019-11-19 11:41   20191119_114103.braid/data_association.csv.gz
 20961850  2019-11-19 12:17   20191119_114103.braid/data2d_distorted.csv.gz
---------                     -------
 22434126                     17 files
</code></pre>
<h3><a class="header" href="#contents-of-a-braidz-file" id="contents-of-a-braidz-file">Contents of a <code>.braidz</code> file</a></h3>
<p>The most important tables in the <code>.braidz</code> file are <code>kalman_estimates</code>, with the
3D tracking results, and <code>data2d_distorted</code>, with the 2D camera detections.</p>
<h4><a class="header" href="#data2d_distorted-table" id="data2d_distorted-table"><code>data2d_distorted</code> table</a></h4>
<p>The <code>data2d_distorted</code> table contains the raw (2D) camera detections and is
typically quite large. See the documentation for the row type
<a href="https://strawlab.org/strand-braid-api-docs/latest/flydra_types/struct.Data2dDistortedRow.html">Data2dDistortedRow</a>.
This file is important for carrying synchronization data between cameras. For
example, when saving videos, the timing data carried by the
<a href="https://strawlab.org/strand-braid-api-docs/latest/flydra_types/struct.Data2dDistortedRow.html#structfield.frame">frame</a>
and
<a href="https://strawlab.org/strand-braid-api-docs/latest/flydra_types/struct.Data2dDistortedRow.html#structfield.block_id">block_id</a>
fields is important.</p>
<h4><a class="header" href="#kalman_estimates-table" id="kalman_estimates-table"><code>kalman_estimates</code> table</a></h4>
<p>The <code>kalman_estimates</code> tables contains the estimated state (positions and
velocities) of each tracked object in addition to the estimated covariance. See
the documentation for the row type
<a href="https://strawlab.org/strand-braid-api-docs/latest/flydra_types/struct.KalmanEstimatesRow.html">KalmanEstimatesRow</a>.</p>
<h4><a class="header" href="#data_association-table" id="data_association-table"><code>data_association</code> table</a></h4>
<p>The <code>data_association</code> table contains which camera detections contributed to
estimating the state of which objects in the <code>kalman_estimates</code> table. See the
documentation for the row type
<a href="https://strawlab.org/strand-braid-api-docs/latest/flydra_types/struct.DataAssocRow.html">DataAssocRow</a>.</p>
<h3><a class="header" href="#chunked-iteration-of-kalman_estimates" id="chunked-iteration-of-kalman_estimates">Chunked iteration of <code>kalman_estimates</code></a></h3>
<p>The primary tracking results are in the <code>kalman_estimates</code> table. There can
often be many gigabytes of data here, and thus it is useful to iterate over
duration-defined chunks in this file. This way, the entire <code>.braidz</code> file never
needs to be decompressed and the all results do not need to fit in your
computer's memory at once.</p>
<p>This following example uses the <code>pybraidz_chunked_iter</code> Python package. It
iterates over chunks of the file <code>20201104_174158.braidz</code>, which can be
downloaded <a href="https://strawlab-cdn.com/assets/20201104_174158.braidz">here</a>:</p>
<pre><code class="language-python">import pybraidz_chunked_iter # install with &quot;pip install pybraidz_chunked_iter&quot;
import pandas as pd

# The filename of the braidz file
braidz_fname = &quot;20201104_174158.braidz&quot;

# Open the braidz file and create chunks of 60 second durations.
estimates_chunker = pybraidz_chunked_iter.chunk_on_duration(braidz_fname, 60)

# One could also create chunks with 100 frames of data.
# estimates_chunker = pybraidz_chunked_iter.chunk_on_num_frames(braidz_fname, 100)

# Iterate over each chunk
for chunk in estimates_chunker:
    print(&quot;Read chunk with %d rows&quot;%(chunk[&quot;n_rows&quot;],))

    # Create a pandas DataFrame with the data from each chunk
    df = pd.DataFrame(data=chunk[&quot;data&quot;])
    print(df)
</code></pre>
<h1><a class="header" href="#3d-tracking-in-braid" id="3d-tracking-in-braid">3D Tracking in Braid</a></h1>
<h2><a class="header" href="#principle-of-operation" id="principle-of-operation">Principle of operation</a></h2>
<p>This page describes the basic principles of how tracking in 3D is implemented by
Braid. A more detailed and more mathematical description can be found in the
paper describing Braid's predecessor, Straw et al. (2011). Please refer to this
for more details.</p>
<p>Straw et al. 2011: Straw AD, Branson K, Neumann TR, Dickinson MH (2011) Multicamera
Realtime 3D Tracking of Multiple Flying Animals. <em>Journal of The Royal Society
Interface 8</em>(11), 395-409.
<a href="http://dx.doi.org/10.1098/rsif.2010.0230">doi:10.1098/rsif.2010.0230</a></p>
<p><img src="images/rsif20100230f02.jpg" alt="images/rsif20100230f02.jpg" />.</p>
<p><strong>Figure 1: Principles of 3D Tracking in Braid.</strong> References in blue refer to
parts of <a href="http://dx.doi.org/10.1098/rsif.2010.0230">Straw et al. (2011)</a>. (a)
Flowchart of operations. (b) Schematic of a two-dimensional camera view showing
the raw images (brown), feature extraction (blue), state estimation (black), and
data association (red). (c) Three-dimensional reconstruction using the EKF uses
prior state estimates (open circle) and observations (blue lines) to construct a
posterior state estimate (filled circle) and covariance ellipsoid (dotted
ellipse). This figure and some caption text reproduced from Figure 2 of <a href="http://dx.doi.org/10.1098/rsif.2010.0230">Straw
et al. (2011)</a> under the Creative
Commons Attribution License.</p>
<p>(TODO: walkthrough of figure above.)</p>
<h2><a class="header" href="#tracking-in-water-with-cameras-out-of-water" id="tracking-in-water-with-cameras-out-of-water">Tracking in water with cameras out of water</a></h2>
<p>One important aspect of Braid not covered in <a href="http://dx.doi.org/10.1098/rsif.2010.0230">Straw et al.
(2011)</a> is the the capability of
tracking fish (or other objects in water) from cameras placed above the water
surface.</p>
<h3><a class="header" href="#refraction" id="refraction">Refraction</a></h3>
<p>When looking through the air-water interface (or any refractive boundary),
objects on the other side appear from a different direction than the direct path
to the object due to <a href="https://en.wikipedia.org/wiki/Refraction">refraction</a>.
Mathematically, refraction is described by <a href="https://en.wikipedia.org/wiki/Fermat%27s_principle">Fermat's principle of least
time</a>, and this forms the
basis of Braid's tracking in water.</p>
<h3><a class="header" href="#principle-of-operation-for-tracking-in-water" id="principle-of-operation-for-tracking-in-water">Principle of operation for tracking in water</a></h3>
<p>When considering the principle of operation of 3D tracking described above, the
primary addition to Braid required for tracking in water is the ability to model
the rays coming from the animal to the camera not as straight lines but rather
having a bend due to refraction. To implement this, the observation model of the
extended Kalman filter is extended to incorporate the air-water boundary so that
it consists of both a 3D camera model and air-water surface model. Thus, during
the update step of the Kalman filter, this non-linear model is linearized about
the expected (<em>a priori</em>) position of the tracked object.</p>
<p>Currently, Braid has a simplification that the model of the air-water boundary
is always fixed at z=0. Thus, anything with z&lt;0 is under water and anything with
z&gt;0 is above water. This implies that the coordinate frame for tracking with an
air-water boundary must have this boundary at z=0 for correct tracking.</p>
<h3><a class="header" href="#how-to-enable-tracking-in-water" id="how-to-enable-tracking-in-water">How to enable tracking in water.</a></h3>
<p>Practically speaking, tracking using the model of an air-water boundary is
enabled by placing the string <code>&lt;water&gt;1.333&lt;/water&gt;</code> the XML camera calibration
file. This will automatically utilize the refractive boundary model described
above with a value for the refractive index of 1.333 for the medium at z&lt;0. As
1.333 is the refractive index of water, it is a model of refraction in water.</p>
<h2><a class="header" href="#tracking-multiple-objects-in-3d" id="tracking-multiple-objects-in-3d">Tracking multiple objects in 3D</a></h2>
<p>It is possible to use Braid to track two or more objects in 3D. Typically this
requires the per-camera, 2D object detection to be set to also detect multiple
objects. Thus, the parameter <code>max_num_points</code> in the Object Detection
configuration of Strand Camera should be set to at least the number of objects
that should be tracked.</p>
<p>To maintain object identity over time, such that a single trajectory is recorded
for a single animal, Braid uses a simple data association algorithm which
assumes independent movement of the tracked objects. This is sufficient in many
cases for tracking animals even when they interact strongly with each other, but
it is typically be necessary to tune relevant tracking and data association
parameters to get the best performance possible.</p>
<h2><a class="header" href="#details-about-how-data-are-processed-online-and-saved-for-later-analysis" id="details-about-how-data-are-processed-online-and-saved-for-later-analysis">Details about how data are processed online and saved for later analysis</a></h2>
<p>While running, Braid saves a copy of all incoming feature detections from the
cameras as a first step prior to inspecting frame numbers and bundling data from
synchronously acquired data from multiple cameras. Combined with issues such as
unreliable networks, this has the unfortunate effect that frames saved to disk
cannot be guaranteed to be monotonically increasing. For online processing to
implement 3D tracking, there is always an idea of &quot;current frame number&quot;. Any
data from prior frames is immediately discarded from further consideration (but
it was saved to disk as described above). If the incoming frame number is larger
than the current frame number, any accumulated data for the &quot;current frame&quot; is
deemed complete and this is bundled for immediate processing. If the incoming
frame number is larger than a single frame from the current frame number,
additional frames of empty data are generated so that the stream of bundled data
is contiguous (with no gaps) up until the incoming frame number, which then
becomes the new &quot;current frame number&quot;.</p>
<p>Note that in post-processing based on data saved in <code>.braidz</code> files, a better
reconstruction can be made than possible in the online approach described above
because data which may have been discarded originally could be incorporated into
the tracking process. Furthermore, because latency is no longer a significant
concern, reconstruction for a particular instant need not be performed with only
historical data but can also incorporate information that occurred after that
instant.</p>
<h1><a class="header" href="#setting-and-optimizing-parameters-for-3d-tracking" id="setting-and-optimizing-parameters-for-3d-tracking">Setting and optimizing parameters for 3D Tracking</a></h1>
<h2><a class="header" href="#object-detection" id="object-detection">Object Detection</a></h2>
<p>The basis of 3D Tracking is a 2D object detection procedure, usually performed
on simultaneously acquired images from at least two cameras.</p>
<p>Object detection is based on background subtraction and feature extraction. In
Braid, these parameters are typically set in the .toml config file specified
when starting the program. When not explicitly specified, default parameters are
used. Within Strand Camera, including when run from within Braid, these
parameters can be set in a running instance. The parameters are specified in a
camera-specific way, meaning that each camera can have its own parameter values.</p>
<p>In Strand Camera, the option <code>Record CSV file</code> will record the object detection
results in CSV format with a header including the object detection parameters in
use at the start of the recording.</p>
<p>The details on implementation and parameters can be found in the
<a href="https://strawlab.org/strand-braid-api-docs/latest/flydra_feature_detector_types/struct.ImPtDetectCfg.html">ImPtDetectCfg</a>
section of the API.</p>
<p>A more technical account of this procedure can be found in <a href="http://dx.doi.org/10.1098/rsif.2010.0230">Straw et al. (2011)</a>.</p>
<!--
### Optimization

 To debug these values for your setup, I recommend saving data to using flydra and inspecting the 2D points detected. I find the flydra_analysis_plot_timeseries_2d_3d program to be most helpful for this. Flydra was designed to accept quite a few false positives at the 2D stage to avoid having any missed detections, so I would err on the side of accepting too many, rather than too few, 2D features detected. Of course too many 2D detections is also problematic, so this requires some tuning. Hopefully the defaults are a good start for your lighting setup.

There is unfortunately no easy procedure for optimizing parameters. For optimizing 2D feature detection parameters, one should examine the features detected in the 2D view (e.g. with the braidz viewer website or relevant notebooks) and make sure that detections are present at times and locations where they should be and absent from times and locations where they should not be.

-->
<h2><a class="header" href="#3d-tracking" id="3d-tracking">3D Tracking</a></h2>
<p>3D tracking is based on data association, which links 2D features from
individual cameras to a 3D model, and an Extended Kalman Filter, which updates
the estimated position and velocity of the 3D model from the 2D features.</p>
<p>The implementation details for the 3D tracking procedures can be found in the
<a href="https://strawlab.org/strand-braid-api-docs/latest/flydra_types/struct.TrackingParams.html">TrackingParams</a>
section of the API.</p>
<!--
### Optimization

For the 3D parameters, this is more difficult. I think I have some emails from the past year or two with Floris van Breugel where I discussed this. Let me see if I can find those.

A principled approach would start with ideas such as these:

 - https://www.robots.ox.ac.uk/~ian/Teaching/Estimation/LectureNotes2.pdf
 - https://arxiv.org/pdf/1807.08855.pdf
-->
<h1><a class="header" href="#calibration-in-braid" id="calibration-in-braid">Calibration in Braid</a></h1>
<h2><a class="header" href="#what-is-a-calibration" id="what-is-a-calibration">What is a calibration?</a></h2>
<p>In our usage here, we refer to a calibration as a model of a camera which allows
us to compute the 2D image location of a given 3D point. Braid can use
calibrations of multiple cameras to calculate the 3D position of a given point
when viewed in 2D camera images.</p>
<p>For a given camera, the calibration is divided into two parts. The &quot;extrinsics&quot;,
or extrinsic parameters, define the pose of the camera. This is the 3D position
and orientation of the camera. The &quot;intrinsics&quot;, or intrinsic parameters, define
the projection of 3D coordinates relative to the camera to an image point in
pixels. In Braid, the camera model is a pinhole model with warping distortion.
The intrinsic parameters include focal length, the pixel coordinates of the
optical axis, and the radial and tangential parameters of a &quot;plumb bob&quot;
distortion model (also called the Brown-Conrady distortion model).</p>
<h2><a class="header" href="#xml-calibration-files-in-braid" id="xml-calibration-files-in-braid">XML calibration files in Braid</a></h2>
<p>The XML calibration files used in Braid are backwards-compatible with those from
Braid's predecessor, Flydra. A braid XML calibration file contains multiple
individual camera calibrations and potentially and &quot;global&quot; information, such as
whether there is an air-water interface for use in the case when cameras are
looking down into water.</p>
<p>While the format of the XML file is specific to Braid, the actual camera
calibration parameters are conventional and could be obtained via other
workflows than that described here. For example, the &quot;traditional&quot; calibration
method from <a href="https://github.com/strawlab/flydra">flydra</a> uses the
<a href="https://github.com/strawlab/MultiCamSelfCal">MultiCamSelfCal (MCSC) library</a>.
There is also the simple <a href="https://strawlab.org/braid-april-cal-webapp/">Braid April Tag Calibration
Tool</a> tool. There is <a href="https://github.com/strawlab/dlt-april-cal/blob/main/tutorial.ipynb">a tutorial
Jupyter
notebook</a>
for a manual approach involving April Tags.</p>
<h2><a class="header" href="#step-0-setup-cameras-zoom-focus-aperture-gain-and-lights" id="step-0-setup-cameras-zoom-focus-aperture-gain-and-lights">Step 0: setup cameras (zoom, focus, aperture, gain) and lights</a></h2>
<p>Setup camera position, zoom, focus (using an object in the tracking volume) and
aperture (slightly stopped down from wide-open). Exposure times and gains are
set in Strand Cam for each camera individually. Note that if you intend to run
at 100 frames per second, exposure times must be less than 10 milliseconds.
These settings (exposure time and gain) are (unfortunately) currently not saved
in any file, and can be set only in the camera settings GUI (in the browser).
The camera keeps these values persistently when it is on, but if it has been
power cycled, these values will be reset.</p>
<p>Try to obtain a luminance distribution which extends across the entire dynamic
range of your sensor (from intensity values 0 to 255) with very little clipping.</p>
<h2><a class="header" href="#step-1-run-checkerboard-calibration-to-get-the-camera-intrinsic-parameters-for-each-camera" id="step-1-run-checkerboard-calibration-to-get-the-camera-intrinsic-parameters-for-each-camera">Step 1: run &quot;Checkerboard Calibration&quot; to get the camera intrinsic parameters for each camera</a></h2>
<p>(There is a script to draw checkerboards as SVG files:
<a href="https://github.com/strawlab/strand-braid/blob/main/strand-braid-user/scripts/draw_checkerboard_svg.py"><code>draw_checkerboard_svg.py</code></a>.)</p>
<p>In Strand Cam, there is a region called &quot;Checkerboard Calibration&quot; which allows
you to calibrate the camera intrinsic parameters. Show a checkerboard to the
camera. You must enter your the checkerboard parameters into the user interface.
For example, a standard 8x8 checkerboard would have 7x7 corners. Try to show the
checkerboard at different distances and angles. Do not forget to show the
checkerboard corners in the corners of the camera field of view. There is a
field which shows the number of checkerboard collected - this should increase as
the system detects checkerboards. When you have gathered a good set of (say, at
least 10) checkerboards, click the &quot;Perform and Save Calibration&quot; button. The
results of this calibration are saved to the directory
<code>$HOME/.config/strand-cam/camera_info</code>.</p>
<p>As an alternative to running this procedure live with Strand Camera, you may
operate on a directory of PNG images and <a href="https://github.com/strawlab/strand-braid/tree/main/strand-cam/strand-cam-offline-checkerboards">the <code>strand-cam-offline-checkerboards</code>
program</a>.</p>
<p>Regardless of whether you create the YAML file containing the camera intrinsic
parameters, the first lines of the YAML file will contain a comment like the following showing the mean reprojection distance.</p>
<pre><code class="language-text"># Mean reprojection distance: 0.49
</code></pre>
<p>The mean reprojection distance is a measure of how well the checkerboard
calibration procedure functioned and shows the mean distance between the images
of the checkerboard corners in the saved images compared to a (re)projection of
the calibration's model of the checkerboard into a synthetic image, and is
measured in units of pixels. The theoretical optimal distance is zero. Typically
one can expect mean reprojection distances of one or two pixels at most.</p>
<p>Repeat this procedure for all cameras before proceeding to the next step.</p>
<h2><a class="header" href="#step-2-place-april-tags-at-known-3d-locations-in-the-scene" id="step-2-place-april-tags-at-known-3d-locations-in-the-scene">Step 2: place April Tags at known 3D locations in the scene</a></h2>
<p>We need to place fiducial markers with known locations in our scene such that
each camera sees several of them. Three markers visible per camera is a
mathematical bare minimum, but more is better. If multiple cameras can see a
single marker, this can be helpful to ensure the calibration of all cameras is
internally consistent.</p>
<p>Store the 3D location of the center of each tag in a <code>markers-3d-coords.csv</code>
file like the following:</p>
<pre><code class="language-csv">id,x,y,z
10,0.265,0.758,0.112
15,-0.520,0.773,0.770
20,-0.241,0.509,0.060
22,-0.501,1.025,1.388
</code></pre>
<p>This is a CSV file giving the April Tag ID number and the X, Y and Z coordinates
of each marker. The coordinate system must be right-handed and the units of each
coordinate are meters.</p>
<h2><a class="header" href="#step-3-record-detections-of-april-tags-from-each-camera" id="step-3-record-detections-of-april-tags-from-each-camera">Step 3: record detections of April Tags from each camera</a></h2>
<p>TODO: write this. Quick hint: use Strand Cam to record an april tag detection
CSV file for each camera.</p>
<h2><a class="header" href="#step-4-estimate-extrinsic-parameters-and-save-braid-xml-calibration-file" id="step-4-estimate-extrinsic-parameters-and-save-braid-xml-calibration-file">Step 4: Estimate extrinsic parameters and save Braid .xml calibration file</a></h2>
<p>TODO: write this. Quick hint: Use <code>braid-april-cal-cli</code> script.</p>
<h3><a class="header" href="#optional-calibration-with-water" id="optional-calibration-with-water">Optional: Calibration with water</a></h3>
<p>As described
<a href="braid_3d_tracking.html#tracking-in-water-with-cameras-out-of-water">here</a>, Braid
can track objects in water. To enable this, place the string
<code>&lt;water&gt;1.333&lt;/water&gt;</code> in the XML camera calibration file.</p>
<h1><a class="header" href="#remote-cameras-for-braid" id="remote-cameras-for-braid">Remote Cameras for Braid</a></h1>
<h2><a class="header" href="#what-are-remote-cameras" id="what-are-remote-cameras">What are &quot;remote cameras&quot;?</a></h2>
<p>A remote camera, in the context of Braid, can be used to connect cameras on
separate computers over the network to an instance of Braid. One or more
instances of Strand Camera can thus run on computers other than the computer on
which Braid is running. Cameras can be specified in the Braid configuration
<code>.toml</code> file as being remote and remote cameras can be mixed with non-remote
cameras.</p>
<p>It can also be useful to launch cameras as &quot;remote cameras&quot; even if they run on
the same computer. For example, this can help distinguishing the source of
messages printed to the terminal.</p>
<h2><a class="header" href="#relevant-aspects-of-braid-configuration" id="relevant-aspects-of-braid-configuration">Relevant aspects of Braid configuration</a></h2>
<p>(Relevant background reading: <a href="braid_configuration_and_launching.html#braid-toml-configuration-files">Braid TOML configuration
files</a>.)</p>
<p>If a particular camera is marked by setting <code>start_backend = &quot;remote&quot;</code> in the
<code>[[cameras]]</code> section of the Braid configuration TOML file, <code>braid run</code> does not
attempt to start the camera but rather waits for a network connection from
Strand Camera. Ensure the <code>start_backend</code> field of each relevant camera (in
<code>[[cameras]]</code>) is set to <code>&quot;remote&quot;</code>.</p>
<p>Only once all cameras listed in the TOML file have connected will Braid
synchronize the cameras and allow recording of data.</p>
<p>You may also want to specifically assign the IP and port of the mainbrain HTTP
server. See the reference documentation for <a href="https://strawlab.org/strand-braid-api-docs/latest/braid_config_data/struct.MainbrainConfig.html#structfield.http_api_server_addr">the <code>http_api_server_addr</code>
field</a>.</p>
<pre><code class="language-toml">[mainbrain]
http_api_server_addr = &quot;0.0.0.0:44444&quot;

[[cameras]]
name = &quot;Camera-1&quot;
start_backend = &quot;remote&quot;

[[cameras]]
name = &quot;Camera-2&quot;
start_backend = &quot;remote&quot;
</code></pre>
<h2><a class="header" href="#starting-a-remote-camera" id="starting-a-remote-camera">Starting a remote camera</a></h2>
<p>When launching Braid with a configuration file as above, the messages printed by
Braid will suggest the relevant arguments to use when starting Strand Camera as
a remote camera for Braid.</p>
<p>To start Strand Camera as a remote camera for Braid, run <code>strand-cam-pylon</code> (or
<code>strand-cam-vimba</code>) with the command line argument <code>--braid-url &lt;URL&gt;</code>
specifying the URL for the braid HTTP address. The camera name should also be
specified on the command line using <code>--camera-name &lt;CAMERA NAME&gt;</code>.</p>
<p>In the following example, the Strand Camera will open the camera named
<code>Camera-12345</code> and will connect to Braid running at <code>http://127.0.0.1:44444</code>.</p>
<pre><code class="language-ignore">strand-cam-pylon --camera-name Camera-12345 --braid-url http://127.0.0.1:44444
</code></pre>
<h1><a class="header" href="#scripting-with-python" id="scripting-with-python">Scripting with Python</a></h1>
<p>Everything in Strand Cam and Braid that can be controlled from the web browser
can also be controlled from a Python script. The general technique is to use a
Python library to connect to a running Strand Cam (or Braid) program exactly
like a web browser does it.</p>
<h2><a class="header" href="#demo-recording-a-video-using-strand-camera-from-a-python-script" id="demo-recording-a-video-using-strand-camera-from-a-python-script">Demo: recording a video using Strand Camera from a Python script</a></h2>
<p>TODO: describe how to use and modify the <a href="https://github.com/strawlab/strand-braid/blob/main/strand-braid-user/scripts/record-mp4-video.py"><code>record-mp4-video.py</code>
demo</a>.</p>
<h2><a class="header" href="#demo-recording-multiple-videos-using-braid-from-a-python-script" id="demo-recording-multiple-videos-using-braid-from-a-python-script">Demo: recording multiple videos using Braid from a Python script</a></h2>
<p>TODO: describe how to use and modify the <a href="strand-braid-user/scripts/record-mp4-video-braid-all-cams.py"><code>record-mp4-video-braid-all-cams.py</code>
demo</a>.</p>
<h2><a class="header" href="#demo-save-preview-images-to-disk-from-strand-camera-using-python" id="demo-save-preview-images-to-disk-from-strand-camera-using-python">Demo: save preview images to disk from Strand Camera using Python</a></h2>
<p>TODO: describe how to use and modify the <a href="https://github.com/strawlab/strand-braid/blob/main/strand-braid-user/scripts/strand_cam_subscriber.py"><code>strand_cam_subscriber.py</code>
demo</a>.</p>
<h2><a class="header" href="#demo-listen-to-realtime-3d-tracking-data-using-python" id="demo-listen-to-realtime-3d-tracking-data-using-python">Demo: listen to realtime 3D tracking data using Python</a></h2>
<p>TODO: describe how to use and modify the <a href="https://github.com/strawlab/strand-braid/blob/main/strand-braid-user/scripts/braid_retransmit_udp.py"><code>braid_retransmit_udp.py</code>
demo</a>.</p>
<h2><a class="header" href="#advanced-automating-manual-actions" id="advanced-automating-manual-actions">Advanced: automating manual actions</a></h2>
<p>TODO: describe how to use the developer tools to watch the network requests from
your browser to view HTTP POST callbacks taken on certain actions.</p>
<h2><a class="header" href="#advanced-running-strand-cam-within-python" id="advanced-running-strand-cam-within-python">Advanced: Running Strand Cam within Python</a></h2>
<p>It is also possible to run strand cam within a Python program. This allows, for
example, to analyze images from within a Python script with minimal latency. See
the
<a href="https://github.com/strawlab/strand-braid/tree/main/py-strandcam">py-strandcam</a>
directory.</p>
<h1><a class="header" href="#processing-recorded-videos-using-braid" id="processing-recorded-videos-using-braid">Processing recorded videos using Braid</a></h1>
<h2><a class="header" href="#overview" id="overview">Overview</a></h2>
<p>The <code>braid-process-video</code> program will takes video files and process them to
produce various outputs.</p>
<!--- todo: convert image to show .mp4 not .mkv -->
<p><img src="images/braid-process-video.png" alt="images/braid-process-video.png" /></p>
<p>As shown in the figure, this program takes <code>.mp4</code> (or <code>.fmf</code>) video input files
saved by Braid and a configuration file and then creates an output <code>.mp4</code> video
which stitches the input videos together. Optionally, it can also plot 2D
detections from a <code>.braidz</code> file on top of the raw video.</p>
<h2><a class="header" href="#note" id="note">Note</a></h2>
<ul>
<li>The input videos must be saved by Braid to ensure that the timestamps for each
frame in the file are correctly stored.</li>
</ul>
<h2><a class="header" href="#example-usage-1-automatic-determination-of-inputs" id="example-usage-1-automatic-determination-of-inputs">Example usage 1: Automatic determination of inputs</a></h2>
<p>If a directory contains a single <code>.braidz</code> file and one or more video files,
<code>braid-process-video</code> can automatically generate a video with default options.
In this case run it like so:</p>
<pre><code class="language-ignore">braid-process-video auto-config --input-dir /path/to/video-and-braidz-files
</code></pre>
<h2><a class="header" href="#example-usage-2-use-of-a-toml-configuration-file" id="example-usage-2-use-of-a-toml-configuration-file">Example usage 2: Use of a <code>.toml</code> configuration file</a></h2>
<p>Here is an example configuration file <code>braid-bundle-videos.toml</code>:</p>
<pre><code class="language-ignore"># The .braidz file with 2D detection data (optional).
input_braidz = &quot;20211011_163203.braidz&quot;

# This stanza specified that an output video will be made.
[[output]]
type = 'video'
filename = 'composite.mp4'

# The following sections specify video sources to use as input.
[[input_video]]
filename = 'movie20211011_163224.mp4'

[[input_video]]
filename = 'movie20211011_163228.mp4'
</code></pre>
<p>With such a configuration file, run the program like so:</p>
<pre><code class="language-ignore">braid-process-video config-toml --config-toml braid-bundle-videos.toml
</code></pre>
<h2><a class="header" href="#todo" id="todo">TODO</a></h2>
<p>There are many more options which can be configured in the <code>.toml</code> configuration
file and they should be documented.</p>
<h1><a class="header" href="#fmf-fly-movie-format---simple-uncompressed-movie-storage-format" id="fmf-fly-movie-format---simple-uncompressed-movie-storage-format">FMF (Fly Movie Format) - simple, uncompressed movie storage format</a></h1>
<p><strong>New users are recommended to use MP4 files for video rather than FMF files.</strong>
Strand Camera supports saving to MP4 files, using several different potential
encoders.</p>
<p>The primary design goals of FMF files are:</p>
<ul>
<li>Single pass, low CPU overhead writing of lossless movies for realtime streaming applications</li>
<li>Precise timestamping for correlation with other activities</li>
<li>Simple format that can be written and read from a variety of languages.</li>
</ul>
<p>These goals are achieved via using a very simple format. After an initial header
containing meta-data such as image size and color coding scheme (e.g.
monochromatic 8 bits per pixel, YUV422, etc.), repeated chunks of raw image data
and timestamp are saved. Because the raw image data from the native camera
driver is saved, no additional processing is performed. Thus, streaming of
movies from camera to disk will keep the CPU free for other tasks, but it will
require a lot of disk space. Furthermore, the disk bandwidth required is
equivalent to the camera bandwidth (unless you save only a region of the images,
or if you only save a fraction of the incoming frames).</p>
<p>The FMF file type defines raw image sequences where each image is stored exactly
in the raw data bytes as they were acquired from the camera together with with a
timestamp. There are two versions implemented, versions 1 and 3 (Version 2 was
briefly used internally and is now best forgotten). Version 1 is deprecated and
new movies should not be written in this format.</p>
<p>A <strong>Rust</strong> implementation to read and write <code>.fmf</code> files can be found in the
<a href="https://github.com/strawlab/strand-braid/tree/main/fmf"><code>github.com/strawlab/strand-braid</code>
repository</a>.</p>
<p>Documentation for the file type and reading/writing <code>.fmf</code> files in <strong>Python</strong>
can be found at the <a href="http://code.astraw.com/projects/motmot/fly-movie-format.html">documentation of
<code>motmot.FlyMovieFormat</code></a>.</p>
<p>A <strong>MATLAB®</strong> implementation can be found in the
<a href="https://github.com/motmot/flymovieformat/tree/master/matlab"><code>github.com/motmot/flymovieformat</code>
repository</a>.</p>
<p>An <strong>R</strong> implementation can be found in the <a href="https://github.com/jefferis/fmfio"><code>github.com/jefferis/fmfio</code>
repository</a>.</p>
<h2><a class="header" href="#converting-movies-to-and-from-fmf-format-with-the-fmf-command-line-program" id="converting-movies-to-and-from-fmf-format-with-the-fmf-command-line-program">Converting movies to and from FMF format with the <code>fmf</code> command line program</a></h2>
<p>The <code>fmf</code> command line program from
<a href="https://github.com/strawlab/strand-braid/tree/main/fmf/fmf-cli">https://github.com/strawlab/strand-braid/tree/main/fmf/fmf-cli</a>
can be used for a variety of tasks with <code>.fmf</code> files, especially converting to
and from other formats.</p>
<p>Here is the output <code>fmf --help</code>:</p>
<pre><code class="language-ignore">strawlab@flycube10:~$
fmf 0.1.0
work with .fmf (fly movie format) files

USAGE:
    fmf &lt;SUBCOMMAND&gt;

FLAGS:
    -h, --help       Prints help information
    -V, --version    Prints version information

SUBCOMMANDS:
    export-fmf       export an fmf file
    export-jpeg      export a sequence of jpeg images
    export-mp4       export to mp4
    export-png       export a sequence of png images
    export-y4m       export to y4m (YUV4MPEG2) format
    help             Prints this message or the help of the given subcommand(s)
    import-images    import a sequence of images, converting it to an FMF file
    info             print information about an fmf file
</code></pre>
<p>See https://github.com/strawlab/strand-braid/tree/main/fmf/fmf-cli for more information.</p>
<h2><a class="header" href="#file-structure" id="file-structure">File Structure</a></h2>
<table><thead><tr><th>FMF File structure</th></tr></thead><tbody>
<tr><td>Header</td></tr>
<tr><td>Frame chunk 0</td></tr>
<tr><td>Frame chunk 1</td></tr>
<tr><td>Frame chunk 2</td></tr>
<tr><td>...</td></tr>
<tr><td>Frame chunk N</td></tr>
</tbody></table>
<p>The chunk size is specified in the header and is equal to the raw frame pixel
data size plus 8 bytes for the timestamp. Thus a 640 pixel wide, 480 pixel high
MONO8 format image would have a <code>chunksize</code> of 307208 (equal to 640 * 480 + 8).</p>
<p>Because the chunk size is constant for all frames, any chunk can be accessed by
computing its position and seeking to that location. For the same reason, the
image data within FMF files can be memory mapped.</p>
<h3><a class="header" href="#header-version-3" id="header-version-3">Header Version 3</a></h3>
<p>This is the preferred header for all new FMF files.</p>
<table><thead><tr><th>Start position</th><th>Type</th><th>Name</th><th>Description</th></tr></thead><tbody>
<tr><td>0</td><td>u32</td><td>version</td><td>Version number (3)</td></tr>
<tr><td>4</td><td>u32</td><td>lenformat</td><td>Length of the subsequent format string</td></tr>
<tr><td>8</td><td>[u8; N]</td><td>format</td><td>ASCII string of N characters containing pixel format, e.g. <code>MONO8</code> or <code>YUV422</code></td></tr>
<tr><td>8+N</td><td>u32</td><td>bpp</td><td>Bits per pixel, e.g. 8</td></tr>
<tr><td>12+N</td><td>u32</td><td>height</td><td>Number of rows of image data</td></tr>
<tr><td>16+N</td><td>u32</td><td>width</td><td>Number of columns of image data</td></tr>
<tr><td>20+N</td><td>u64</td><td>chunksize</td><td>Bytes per &quot;chunk&quot; (timestamp + frame)</td></tr>
<tr><td>28+N</td><td>u64</td><td>n_frames</td><td>Number of frame chunks (0=unknown, read file to find out)</td></tr>
</tbody></table>
<p>For the <code>format</code> field, the following pixel formats are known:</p>
<table><thead><tr><th>Format string</th><th>Description</th></tr></thead><tbody>
<tr><td><code>MONO8</code></td><td>Monochrome data, 8 bits per pixel</td></tr>
<tr><td><code>RAW8:RGGB</code></td><td>Raw Bayer mosaic data, RGGB pattern, 8 bits per pixel</td></tr>
<tr><td><code>RAW8:GBRG</code></td><td>Raw Bayer mosaic data, GBRG pattern, 8 bits per pixel</td></tr>
<tr><td><code>RAW8:GRBG</code></td><td>Raw Bayer mosaic data, GRBG pattern, 8 bits per pixel</td></tr>
<tr><td><code>RAW8:BGGR</code></td><td>Raw Bayer mosaic data, BGGR pattern, 8 bits per pixel</td></tr>
<tr><td><code>YUV422</code></td><td>Packed YUV encoded data, 16 bits per pixel</td></tr>
<tr><td><code>RGB8</code></td><td>Packed RGB encoded data, 24 bits per pixel</td></tr>
</tbody></table>
<p>This list of pixel formats is not exhaustive and other formats can be added.</p>
<h3><a class="header" href="#header-version-1" id="header-version-1">Header Version 1</a></h3>
<p>⚠ This version is deprecated and no new files with this format should be written. ⚠</p>
<p>Only supports MONO8 pixel format.</p>
<table><thead><tr><th>Start position</th><th>Type</th><th>Name</th><th>Description</th></tr></thead><tbody>
<tr><td>0</td><td>u32</td><td>version</td><td>Version number (1)</td></tr>
<tr><td>4</td><td>u32</td><td>height</td><td>Number of rows of image data</td></tr>
<tr><td>8</td><td>u32</td><td>width</td><td>Number of columns of image data</td></tr>
<tr><td>12</td><td>u64</td><td>chunksize</td><td>Bytes per &quot;chunk&quot; (timestamp + frame)</td></tr>
<tr><td>20</td><td>u64</td><td>n_frames</td><td>Number of frames (0=unknown, read file to find out)</td></tr>
</tbody></table>
<h3><a class="header" href="#frame-chunks" id="frame-chunks">Frame Chunks</a></h3>
<p>Frame chunks have an identical format in FMF v1 and v3 files. From a given
camera pixel format and size, they are constant in size and thus the Nth frame
can be accessed by seeking to <code>frame0_offset + n*chunksize</code>. The image data is
uncompressed raw image data as read directly from the camera.</p>
<table><thead><tr><th>Start position within chunk</th><th>Type</th><th>Name</th><th>Description</th></tr></thead><tbody>
<tr><td>0</td><td>f64</td><td>timestamp</td><td>Timestamp (seconds in current epoch)</td></tr>
<tr><td>8</td><td>[u8; N]</td><td>image_data</td><td>Image data</td></tr>
</tbody></table>
<h3><a class="header" href="#types-used-above" id="types-used-above">Types used above</a></h3>
<p>All numbers are little-endian (Intel standard).</p>
<table><thead><tr><th>Type</th><th>size (in bytes)</th><th>description</th></tr></thead><tbody>
<tr><td>[u8; N]</td><td>N</td><td>variable length buffer of characters</td></tr>
<tr><td>u32</td><td>4</td><td>unsigned 32 bit integer</td></tr>
<tr><td>u64</td><td>8</td><td>unsigned 64 bit integer</td></tr>
<tr><td>f64</td><td>8</td><td>64 bit floating point number</td></tr>
</tbody></table>
<h1><a class="header" href="#troubleshooting" id="troubleshooting">Troubleshooting</a></h1>
<h2><a class="header" href="#synchronization-problems" id="synchronization-problems">synchronization problems</a></h2>
<h2><a class="header" href="#any-other-problem-or-question" id="any-other-problem-or-question">any other problem or question</a></h2>
<p>Please <a href="https://github.com/strawlab/strand-braid/issues">report any issues you
face</a> or <a href="https://groups.google.com/forum/#!forum/multicams">ask any questions you
may have</a>.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        

        
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        

        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
        
        

    </body>
</html>
