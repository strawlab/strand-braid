<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>User's Guide for Braid and Strand Camera</title>
        
        <meta name="robots" content="noindex" />
        
        


        <!-- Custom HTML head -->
        


        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="Low latency image processing and tracking">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        
        <link rel="icon" href="favicon.svg">
        
        
        <link rel="shortcut icon" href="favicon.png">
        
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        
        <link rel="stylesheet" href="css/print.css" media="print">
        

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        
        <link rel="stylesheet" href="fonts/fonts.css">
        

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="braid-and-strand-camera.html">Braid and Strand Camera</a></li><li class="chapter-item expanded "><a href="hardware-selection.html"><strong aria-hidden="true">1.</strong> Hardware selection</a></li><li class="chapter-item expanded "><a href="installation.html"><strong aria-hidden="true">2.</strong> Installation</a></li><li class="chapter-item expanded "><a href="braidz-files.html"><strong aria-hidden="true">3.</strong> BRAIDZ files and Analysis Scripts</a></li><li class="chapter-item expanded "><a href="braid_3d_tracking.html"><strong aria-hidden="true">4.</strong> Braid: 3D Tracking</a></li><li class="chapter-item expanded "><a href="parameters_for_object_detection_and_tracking.html"><strong aria-hidden="true">5.</strong> Parameters for Object Detection and Tracking</a></li><li class="chapter-item expanded "><a href="braid_calibration.html"><strong aria-hidden="true">6.</strong> Braid: 3D Calibration</a></li><li class="chapter-item expanded "><a href="braid_remote_cameras.html"><strong aria-hidden="true">7.</strong> Braid: Remote cameras</a></li><li class="chapter-item expanded "><a href="scripting-with-python.html"><strong aria-hidden="true">8.</strong> Scripting with Python</a></li><li class="chapter-item expanded "><a href="processing-saved-videos.html"><strong aria-hidden="true">9.</strong> Processing saved videos</a></li><li class="chapter-item expanded "><a href="fmf_format.html"><strong aria-hidden="true">10.</strong> Fly Movie Format</a></li><li class="chapter-item expanded "><a href="troubleshooting.html"><strong aria-hidden="true">11.</strong> Troubleshooting</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        
                    </div>

                    <h1 class="menu-title">User's Guide for Braid and Strand Camera</h1>

                    <div class="right-buttons">
                        
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                        
                        <a href="https://github.com/strawlab/strand-braid/tree/main/strand-braid-user/users-guide" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                        
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1><a class="header" href="#braid-and-strand-camera" id="braid-and-strand-camera">Braid and Strand Camera</a></h1>
<p>This is the User's Guide for <a href="https://strawlab.org/braid/">Braid</a> and <a href="https://strawlab.org/strand-cam/">Strand
Camera</a>.</p>
<p>Braid and Strand Camera are free and open source. You can find the source code
on <a href="https://github.com/strawlab/strand-braid">GitHub</a>. Issues and feature
requests can be posted on the <a href="https://github.com/strawlab/strand-braid/issues">GitHub issue
tracker</a>.</p>
<h3><a class="header" href="#about-this-book" id="about-this-book">About this book</a></h3>
<p>The source code for this documentation is at
<a href="https://github.com/strawlab/strand-braid/tree/main/strand-braid-user/users-guide">github.com/strawlab/strand-braid/tree/main/strand-braid-user/users-guide</a>.
This book is made with <a href="https://rust-lang.github.io/mdBook/">mdBook</a>.</p>
<h1><a class="header" href="#hardware-selection" id="hardware-selection">Hardware selection</a></h1>
<h2><a class="header" href="#pc-requirements" id="pc-requirements">PC requirements</a></h2>
<ul>
<li>Supports Ubuntu 20.04 amd64 operating system. This is currently our only
supported platform.</li>
<li>Fast CPU. Currently an Intel CPU is recommended due to the use of the Intel
Integrated Performance Primitives Library.</li>
<li>Memory usage is not expected to be particularly high, because processing
occurs in realtime.</li>
<li>Sufficient and fast interfaces to cameras. If your cameras are USB3 or Gigabit
ethernet, your computer needs to support enough bandwidth.</li>
<li>Disk space and speed. For realtime tracking, the tracking data is only modest
in size and so no particularly high performance requirements exist. With
Nvidia hardware that supports NVENC hardware-accelerated encoding (see below),
compressed, H.264 encoded video can be saved to MP4 files with also only
modest CPU and disk requirements are present. For streaming uncompressed, raw
video to disk (with MP4 or the FMF format), very fast disks and lots of disk
space are required.</li>
</ul>
<h3><a class="header" href="#hardware-accelerated-video-encoding-using-nvidia-video-cards" id="hardware-accelerated-video-encoding-using-nvidia-video-cards">Hardware-accelerated video encoding using nvidia video cards</a></h3>
<p>NVIDIA video encoding hardware is optionally used to encode H.264 videos in the
MP4 format. This is very nice because it takes almost no CPU and full framerate
videos can be recorded from your cameras during live tracking with little or no
loss of performance. This depends on NVIDIA's library called NVENC. Please see
NVIDIA's site for <a href="https://developer.nvidia.com/video-encode-and-decode-gpu-support-matrix-new">supported
hardware</a>.
Note in particular the limit of three encode sessions with the consumer
(GeForce) hardware that does not exist on many of their professional (Quadro)
cards.</p>
<h2><a class="header" href="#camera-requirements" id="camera-requirements">Camera requirements</a></h2>
<p>Currently, Basler cameras using the Pylon API are the only supported cameras. We
plan to support cameras from Allied Vision using the Vimba API in late 2021 or 2022.</p>
<h3><a class="header" href="#basler-cameras" id="basler-cameras">Basler cameras</a></h3>
<p>Due to the use of the Pylon API, any camera which can be used in the Pylon
Viewer can be used in principle. In practice, we regularly test with the
following cameras:</p>
<ul>
<li>Basler a2A1920-160umPRO</li>
<li>Basler a2A1920-160umBAS</li>
<li>Basler acA1300-200um</li>
<li>Basler acA640-120gm</li>
</ul>
<h3><a class="header" href="#allied-vision-cameras-planned-for-late-2021-or-2022" id="allied-vision-cameras-planned-for-late-2021-or-2022">Allied Vision cameras (Planned for late 2021 or 2022)</a></h3>
<p>Due to the use of the Vimba API, any camera which can be used in the Vimba
Viewer can be used in principle. In practice, we intend to use the following
cameras:</p>
<ul>
<li>Allied Vision Alvium 1800 U-240m</li>
</ul>
<h1><a class="header" href="#installation" id="installation">Installation</a></h1>
<h2><a class="header" href="#software-installation" id="software-installation">Software installation</a></h2>
<p>Download releases from <a href="https://github.com/strawlab/strand-braid/releases">our releases
page</a></p>
<h2><a class="header" href="#hardware-installation" id="hardware-installation">Hardware installation</a></h2>
<h3><a class="header" href="#cameras" id="cameras">Cameras</a></h3>
<p>Currently only Basler cameras are supported. We use Basler's Pylon library to
access the cameras.</p>
<p>Support for other cameras is planned.</p>
<h3><a class="header" href="#trigger-box" id="trigger-box">Trigger box</a></h3>
<p>Braid uses the <a href="https://github.com/strawlab/triggerbox">Straw Lab Triggerbox</a>
hardware to synchronize the cameras. This is based on an Arduino
microcontroller.</p>
<h3><a class="header" href="#trigger-cables" id="trigger-cables">Trigger cables</a></h3>
<p>TODO: write this and describe how to check everything is working.</p>
<h1><a class="header" href="#braidz-files" id="braidz-files"><code>.braidz</code> files</a></h1>
<p>A <code>.braidz</code> file contains the results of realtime tracking, the tracking
parameters, and so on.</p>
<h2><a class="header" href="#viewer" id="viewer">Viewer</a></h2>
<p>A viewer for <code>.braidz</code> files is at <a href="https://braidz.strawlab.org/">braidz.strawlab.org</a>.</p>
<h2><a class="header" href="#analysis-scripts" id="analysis-scripts">Analysis scripts</a></h2>
<p>Scripts to analyze your <code>.braidz</code> files can be found at <a href="https://github.com/strawlab/strand-braid/tree/main/strand-braid-user/analysis">github.com/strawlab/strand-braid/tree/main/strand-braid-user/analysis</a>.</p>
<h3><a class="header" href="#latency-analysis" id="latency-analysis">Latency Analysis</a></h3>
<p>To analyze the latency of your setup with Braid, you can use the Jupyter Notebook <code>braid-latency-analysis.ipynb</code>.</p>
<h3><a class="header" href="#content-analysis" id="content-analysis">Content analysis</a></h3>
<p>The Jupyter Notebook <code>braidz-contents.ipynb</code> can be used to view the Kalman estimates, the raw 2D detections, data on the association of cameras, and data on associations between 2D detection and 3D Tracking in your <code>.braidz</code> file.</p>
<h2><a class="header" href="#plotting" id="plotting">Plotting</a></h2>
<p>The following plots were made with the file
<a href="https://strawlab-cdn.com/assets/20201112_133722.braidz">20201112_133722.braidz</a>.
The scripts can be accessed at
<a href="https://github.com/strawlab/strand-braid/tree/main/strand-braid-user/analysis">github.com/strawlab/strand-braid/tree/main/strand-braid-user/analysis</a>.
A Jupyter Notebook to create all of these plots can be found in <code>braid-plotting.ipynb</code> in the same folder.</p>
<h3><a class="header" href="#braid-analysis-plot-data2d-timeseriespy" id="braid-analysis-plot-data2d-timeseriespy"><code>braid-analysis-plot-data2d-timeseries.py</code></a></h3>
<p><img src="braid-analysis-plot-data2d-timeseries.png" alt="braid-analysis-plot-data2d-timeseries.png" /></p>
<h3><a class="header" href="#braid-analysis-plot-kalman-estimates-timeseriespy" id="braid-analysis-plot-kalman-estimates-timeseriespy"><code>braid-analysis-plot-kalman-estimates-timeseries.py</code></a></h3>
<p><img src="braid-analysis-plot-kalman-estimates-timeseries.png" alt="braid-analysis-plot-kalman-estimates-timeseries.png" /></p>
<h3><a class="header" href="#braid-analysis-plot3dpy" id="braid-analysis-plot3dpy"><code>braid-analysis-plot3d.py</code></a></h3>
<p><img src="braid-analysis-plot3d.png" alt="braid-analysis-plot3d.png" /></p>
<h2><a class="header" href="#file-format" id="file-format">File Format</a></h2>
<p>A <code>.braidz</code> file is actually a ZIP file with specific contents. It can be
helpful to know about these specifics when problems arise.</p>
<h3><a class="header" href="#showing-the-contents-of-a-braidz-file" id="showing-the-contents-of-a-braidz-file">Showing the contents of a <code>.braidz</code> file</a></h3>
<p>You can show the filenames inside a .braidz file with
<code>unzip -l FILENAME.braidz</code>.</p>
<h3><a class="header" href="#extracting-a-braidz-file" id="extracting-a-braidz-file">Extracting a <code>.braidz</code> file</a></h3>
<p>You can extract a <code>.braidz</code> file to its contents with <code>unzip FILENAME.braidz</code>.</p>
<h3><a class="header" href="#creating-a-braidz-file" id="creating-a-braidz-file">Creating a <code>.braidz</code> file</a></h3>
<p>You can create a new <code>.braidz</code> file with:</p>
<pre><code class="language-ignore">cd BRAID_DIR
zip ../FILENAME.braidz *
</code></pre>
<p>Note, your <code>.braidz</code> file should look like this - with no directories other than
<code>images/</code>.</p>
<pre><code class="language-ignore">$ unzip -l 20191125_093257.braidz
Archive:  20191125_093257.braidz
zip-rs
  Length      Date    Time    Name
---------  ---------- -----   ----
       97  2019-11-25 09:33   README.md
      155  2019-11-25 09:33   braid_metadata.yml
        0  2019-11-25 09:33   images/
   308114  2019-11-25 09:33   images/Basler_22005677.png
   233516  2019-11-25 09:33   images/Basler_22139107.png
   283260  2019-11-25 09:33   images/Basler_22139109.png
   338040  2019-11-25 09:33   images/Basler_22139110.png
       78  2019-11-25 09:33   cam_info.csv.gz
     2469  2019-11-25 09:33   calibration.xml
      397  2019-11-25 09:33   textlog.csv.gz
   108136  2019-11-25 09:33   kalman_estimates.csv.gz
      192  2019-11-25 09:33   trigger_clock_info.csv.gz
       30  2019-11-25 09:33   experiment_info.csv.gz
     2966  2019-11-25 09:33   data_association.csv.gz
   138783  2019-11-25 09:33   data2d_distorted.csv.gz
---------                     -------
  1416233                     15 files
</code></pre>
<p>Note that the following is NOT a valid <code>.braidz</code> file because it has a leading
directory name for each entry.</p>
<pre><code class="language-ignore">$ unzip -l 20191119_114103.NOT-A-VALID-BRAIDZ
Archive:  20191119_114103.NOT-A-VALID-BRAIDZ
  Length      Date    Time    Name
---------  ---------- -----   ----
        0  2019-11-19 11:41   20191119_114103.braid/
       97  2019-11-19 11:41   20191119_114103.braid/README.md
      155  2019-11-19 11:41   20191119_114103.braid/braid_metadata.yml
        0  2019-11-19 11:41   20191119_114103.braid/images/
   320906  2019-11-19 11:41   20191119_114103.braid/images/Basler_22005677.png
   268847  2019-11-19 11:41   20191119_114103.braid/images/Basler_22139107.png
   308281  2019-11-19 11:41   20191119_114103.braid/images/Basler_22139109.png
   346232  2019-11-19 11:41   20191119_114103.braid/images/Basler_22139110.png
   225153  2019-11-19 11:41   20191119_114103.braid/images/Basler_40019416.png
       86  2019-11-19 11:41   20191119_114103.braid/cam_info.csv.gz
     2469  2019-11-19 11:41   20191119_114103.braid/calibration.xml
       10  2019-11-19 11:41   20191119_114103.braid/textlog.csv.gz
       10  2019-11-19 11:41   20191119_114103.braid/kalman_estimates.csv.gz
       10  2019-11-19 11:41   20191119_114103.braid/trigger_clock_info.csv.gz
       10  2019-11-19 11:41   20191119_114103.braid/experiment_info.csv.gz
       10  2019-11-19 11:41   20191119_114103.braid/data_association.csv.gz
 20961850  2019-11-19 12:17   20191119_114103.braid/data2d_distorted.csv.gz
---------                     -------
 22434126                     17 files
</code></pre>
<h3><a class="header" href="#contents-of-a-braidz-file" id="contents-of-a-braidz-file">Contents of a <code>.braidz</code> file</a></h3>
<p>The most important tables in the <code>.braidz</code> file are <code>kalman_estimates</code>, with the
3D tracking results, and <code>data2d_distorted</code>, with the 2D camera detections.</p>
<h4><a class="header" href="#data2d_distorted-table" id="data2d_distorted-table"><code>data2d_distorted</code> table</a></h4>
<p>The <code>data2d_distorted</code> table contains the raw (2D) camera detections and is
typically quite large. See the documentation for the row type
<a href="https://strawlab.org/strand-braid-api-docs/latest/flydra_types/struct.Data2dDistortedRow.html">Data2dDistortedRow</a>.
This file is important for carrying synchronization data between cameras. For
example, when saving videos, the timing data carried by the
<a href="https://strawlab.org/strand-braid-api-docs/latest/flydra_types/struct.Data2dDistortedRow.html#structfield.frame">frame</a>
and
<a href="https://strawlab.org/strand-braid-api-docs/latest/flydra_types/struct.Data2dDistortedRow.html#structfield.block_id">block_id</a>
fields is important.</p>
<h4><a class="header" href="#kalman_estimates-table" id="kalman_estimates-table"><code>kalman_estimates</code> table</a></h4>
<p>The <code>kalman_estimates</code> tables contains the estimated state (positions and
velocities) of each tracked object in addition to the estimated covariance. See
the documentation for the row type
<a href="https://strawlab.org/strand-braid-api-docs/latest/flydra_types/struct.KalmanEstimatesRow.html">KalmanEstimatesRow</a>.</p>
<h4><a class="header" href="#data_association-table" id="data_association-table"><code>data_association</code> table</a></h4>
<p>The <code>data_association</code> table contains which camera detections contributed to
estimating the state of which objects in the <code>kalman_estimates</code> table. See the
documentation for the row type
<a href="https://strawlab.org/strand-braid-api-docs/latest/flydra_types/struct.DataAssocRow.html">DataAssocRow</a>.</p>
<h3><a class="header" href="#chunked-iteration-of-kalman_estimates" id="chunked-iteration-of-kalman_estimates">Chunked iteration of <code>kalman_estimates</code></a></h3>
<p>The primary tracking results are in the <code>kalman_estimates</code> table. There can
often be many gigabytes of data here, and thus it is useful to iterate over
duration-defined chunks in this file. This way, the entire <code>.braidz</code> file never
needs to be decompressed and the all results do not need to fit in your
computer's memory at once.</p>
<p>This following example uses the <code>pybraidz_chunked_iter</code> Python package. It
iterates over chunks of the file <code>20201104_174158.braidz</code>, which can be
downloaded <a href="https://strawlab-cdn.com/assets/20201104_174158.braidz">here</a>:</p>
<pre><code class="language-python">import pybraidz_chunked_iter # install with &quot;pip install pybraidz_chunked_iter&quot;
import pandas as pd

# The filename of the braidz file
braidz_fname = &quot;20201104_174158.braidz&quot;

# Open the braidz file and create chunks of 60 second durations.
estimates_chunker = pybraidz_chunked_iter.chunk_on_duration(braidz_fname, 60)

# One could also create chunks with 100 frames of data.
# estimates_chunker = pybraidz_chunked_iter.chunk_on_num_frames(braidz_fname, 100)

# Iterate over each chunk
for chunk in estimates_chunker:
    print(&quot;Read chunk with %d rows&quot;%(chunk[&quot;n_rows&quot;],))

    # Create a pandas DataFrame with the data from each chunk
    df = pd.DataFrame(data=chunk[&quot;data&quot;])
    print(df)
</code></pre>
<h1><a class="header" href="#3d-tracking-in-braid" id="3d-tracking-in-braid">3D Tracking in Braid</a></h1>
<h2><a class="header" href="#principle-of-operation" id="principle-of-operation">Principle of operation</a></h2>
<p>This page describes the basic principles of how tracking in 3D is implemented by
Braid. A more detailed and more mathematical description can be found in the
paper describing Braid's predecessor, Straw et al. (2011). Please refer to this
for more details.</p>
<p>Straw et al. 2011: Straw AD, Branson K, Neumann TR, Dickinson MH (2011) Multicamera
Realtime 3D Tracking of Multiple Flying Animals. <em>Journal of The Royal Society
Interface 8</em>(11), 395-409.
<a href="http://dx.doi.org/10.1098/rsif.2010.0230">doi:10.1098/rsif.2010.0230</a></p>
<p><img src="rsif20100230f02.jpg" alt="rsif20100230f02.jpg" />.</p>
<p><strong>Figure 1: Principles of 3D Tracking in Braid.</strong> References in blue refer to
parts of <a href="http://dx.doi.org/10.1098/rsif.2010.0230">Straw et al. (2011)</a>. (a)
Flowchart of operations. (b) Schematic of a two-dimensional camera view showing
the raw images (brown), feature extraction (blue), state estimation (black), and
data association (red). (c) Three-dimensional reconstruction using the EKF uses
prior state estimates (open circle) and observations (blue lines) to construct a
posterior state estimate (filled circle) and covariance ellipsoid (dotted
ellipse). This figure and some caption text reproduced from Figure 2 of <a href="http://dx.doi.org/10.1098/rsif.2010.0230">Straw
et al. (2011)</a> under the Creative
Commons Attribution License.</p>
<p>(TODO: walkthrough of figure above.)</p>
<h2><a class="header" href="#tracking-in-water-with-cameras-out-of-water" id="tracking-in-water-with-cameras-out-of-water">Tracking in water with cameras out of water</a></h2>
<p>One important aspect of Braid not covered in <a href="http://dx.doi.org/10.1098/rsif.2010.0230">Straw et al.
(2011)</a> is the the capability of
tracking fish (or other objects in water) from cameras placed above the water
surface.</p>
<h3><a class="header" href="#refraction" id="refraction">Refraction</a></h3>
<p>When looking through the air-water interface (or any refractive boundary),
objects on the other side appear from a different direction than the direct path
to the object due to <a href="https://en.wikipedia.org/wiki/Refraction">refraction</a>.
Mathematically, refraction is described by <a href="https://en.wikipedia.org/wiki/Fermat%27s_principle">Fermat's principle of least
time</a>, and this forms the
basis of Braid's tracking in water.</p>
<h3><a class="header" href="#principle-of-operation-for-tracking-in-water" id="principle-of-operation-for-tracking-in-water">Principle of operation for tracking in water</a></h3>
<p>When considering the principle of operation of 3D tracking described above, the
primary addition to Braid required for tracking in water is the ability to model
the rays coming from the animal to the camera not as straight lines but rather
having a bend due to refraction. To implement this, the observation model of the
extended Kalman filter is extended to incorporate the air-water boundary so that
it consists of both a 3D camera model and air-water surface model. Thus, during
the update step of the Kalman filter, this non-linear model is linearized about
the expected (<em>a priori</em>) position of the tracked object.</p>
<p>Currently, Braid has a simplification that the model of the air-water boundary
is always fixed at z=0. Thus, anything with z&lt;0 is under water and anything with
z&gt;0 is above water. This implies that the coordinate frame for tracking with an
air-water boundary must have this boundary at z=0 for correct tracking.</p>
<h3><a class="header" href="#how-to-enable-tracking-in-water" id="how-to-enable-tracking-in-water">How to enable tracking in water.</a></h3>
<p>Practically speaking, tracking using the model of an air-water boundary is
enabled by placing the string <code>&lt;water&gt;1.333&lt;/water&gt;</code> the XML camera calibration
file. This will automatically utilize the refractive boundary model described
above with a value for the refractive index of 1.333 for the medium at z&lt;0. As
1.333 is the refractive index of water, it is a model of refraction in water.</p>
<h2><a class="header" href="#tracking-multiple-objects-in-3d" id="tracking-multiple-objects-in-3d">Tracking multiple objects in 3D</a></h2>
<p>It is possible to use Braid to track two or more objects in 3D. Typically this
requires the per-camera, 2D object detection to be set to also detect multiple
objects. Thus, the parameter <code>max_num_points</code> in the Object Detection
configuration of Strand Camera should be set to at least the number of objects
that should be tracked.</p>
<p>To maintain object identity over time, such that a single trajectory is recorded
for a single animal, Braid uses a simple data association algorithm which
assumes independent movement of the tracked objects. This is sufficient in many
cases for tracking animals even when they interact strongly with each other, but
it is typically be necessary to tune relevant tracking and data association
parameters to get the best performance possible.</p>
<h2><a class="header" href="#details-about-how-data-are-processed-online-and-saved-for-later-analysis" id="details-about-how-data-are-processed-online-and-saved-for-later-analysis">Details about how data are processed online and saved for later analysis</a></h2>
<p>While running, Braid saves a copy of all incoming feature detections from the
cameras as a first step prior to inspecting frame numbers and bundling data from
synchronously acquired data from multiple cameras. Combined with issues such as
unreliable networks, this has the unfortunate effect that frames saved to disk
cannot be guaranteed to be monotonically increasing. For online processing to
implement 3D tracking, there is always an idea of &quot;current frame number&quot;. Any
data from prior frames is immediately discarded from further consideration (but
it was saved to disk as described above). If the incoming frame number is larger
than the current frame number, any accumulated data for the &quot;current frame&quot; is
deemed complete and this is bundled for immediate processing. If the incoming
frame number is larger than a single frame from the current frame number,
additional frames of empty data are generated so that the stream of bundled data
is contiguous (with no gaps) up until the incoming frame number, which then
becomes the new &quot;current frame number&quot;.</p>
<p>Note that in post-processing based on data saved in <code>.braidz</code> files, a better
reconstruction can be made than possible in the online approach described above
because data which may have been discarded originally could be incorporated into
the tracking process. Furthermore, because latency is no longer a significant
concern, reconstruction for a particular instant need not be performed with only
historical data but can also incorporate information that occurred after that
instant.</p>
<h1><a class="header" href="#setting-and-optimizing-parameters-for-3d-tracking" id="setting-and-optimizing-parameters-for-3d-tracking">Setting and optimizing parameters for 3D Tracking</a></h1>
<h2><a class="header" href="#object-detection" id="object-detection">Object Detection</a></h2>
<p>The basis of 3D Tracking is a 2D object detection procedure, usually performed
on simultaneously acquired images from at least two cameras.</p>
<p>Object detection is based on background subtraction and feature extraction. In
Braid, these parameters are typically set in the .toml config file specified
when starting the program. When not explicitly specified, default parameters are
used. Within Strand Camera, including when run from within Braid, these
parameters can be set in a running instance. The parameters are specified in a
camera-specific way, meaning that each camera can have its own parameter values.</p>
<p>In Strand Camera, the option <code>Record CSV file</code> will record the object detection
results in CSV format with a header including the object detection parameters in
use at the start of the recording.</p>
<p>The details on implementation and parameters can be found in the
<a href="https://strawlab.org/strand-braid-api-docs/latest/flydra_feature_detector_types/struct.ImPtDetectCfg.html">ImPtDetectCfg</a>
section of the API.</p>
<p>A more technical account of this procedure can be found in <a href="http://dx.doi.org/10.1098/rsif.2010.0230">Straw et al. (2011)</a>.</p>
<!--
### Optimization

 To debug these values for your setup, I recommend saving data to using flydra and inspecting the 2D points detected. I find the flydra_analysis_plot_timeseries_2d_3d program to be most helpful for this. Flydra was designed to accept quite a few false positives at the 2D stage to avoid having any missed detections, so I would err on the side of accepting too many, rather than too few, 2D features detected. Of course too many 2D detections is also problematic, so this requires some tuning. Hopefully the defaults are a good start for your lighting setup.

There is unfortunately no easy procedure for optimizing parameters. For optimizing 2D feature detection parameters, one should examine the features detected in the 2D view (e.g. with the braidz viewer website or relevant notebooks) and make sure that detections are present at times and locations where they should be and absent from times and locations where they should not be.

-->
<h2><a class="header" href="#3d-tracking" id="3d-tracking">3D Tracking</a></h2>
<p>3D tracking is based on data association, which links 2D features from
individual cameras to a 3D model, and an Extended Kalman Filter, which updates
the estimated position and velocity of the 3D model from the 2D features.</p>
<p>The implementation details for the 3D tracking procedures can be found in the
<a href="https://strawlab.org/strand-braid-api-docs/latest/flydra_types/struct.TrackingParams.html">TrackingParams</a>
section of the API.</p>
<!--
### Optimization

For the 3D parameters, this is more difficult. I think I have some emails from the past year or two with Floris van Breugel where I discussed this. Let me see if I can find those.

A principled approach would start with ideas such as these:

 - https://www.robots.ox.ac.uk/~ian/Teaching/Estimation/LectureNotes2.pdf
 - https://arxiv.org/pdf/1807.08855.pdf
-->
<h1><a class="header" href="#calibration-in-braid" id="calibration-in-braid">Calibration in Braid</a></h1>
<h2><a class="header" href="#what-is-a-calibration" id="what-is-a-calibration">What is a calibration?</a></h2>
<p>In our usage here, we refer to a calibration as a model of a camera which allows
us to compute the 2D image location of a given 3D point. Braid can use
calibrations of multiple cameras to calculate the 3D position of a given point
when viewed in 2D camera images.</p>
<p>For a given camera, the calibration is divided into two parts. The &quot;extrinsics&quot;,
or extrinsic parameters, define the pose of the camera. This is the 3D position
and orientation of the camera. The &quot;intrinsics&quot;, or intrinsic parameters, define
the projection of 3D coordinates relative to the camera to an image point in
pixels. In Braid, the camera model is a pinhole model with warping distortion.
The intrinsic parameters include focal length, the pixel coordinates of the
optical axis, and the radial and tangential parameters of a &quot;plumb bob&quot;
distortion model (also called the Brown-Conrady distortion model).</p>
<h2><a class="header" href="#xml-calibration-files-in-braid" id="xml-calibration-files-in-braid">XML calibration files in Braid</a></h2>
<p>The XML calibration files used in Braid are backwards-compatible with those from
Braid's predecessor, Flydra. Several of the steps described here also use tools
from Flydra.</p>
<h2><a class="header" href="#step-1-setup-cameras-zoom-focus-aperture-gain-and-lights" id="step-1-setup-cameras-zoom-focus-aperture-gain-and-lights">Step 1: setup cameras (zoom, focus, aperture, gain) and lights</a></h2>
<p>Setup camera position, zoom, focus (using an object in the tracking volume) and
aperture (slightly stopped down from wide-open). Exposure times and gains are
set in Strand Cam for each camera individually. Note that if you intend to run
at 100 frames per second, exposure times must be less than 10 milliseconds.
These settings (exposure time and gain) are (unfortunately) currently not saved
in any file, and can be set only in the camera settings GUI (in the browser).
The camera keeps these values persistently when it is on, but if it has been
power cycled, it will reset to new values.</p>
<p>Try to a luminance distribution which extends across the entire dynamic range of
your sensor (from intensity values 0 to 255) with very little clipping.</p>
<h2><a class="header" href="#step-2-run-checkerboard-calibration-to-get-the-camera-intrinsic-parameters" id="step-2-run-checkerboard-calibration-to-get-the-camera-intrinsic-parameters">Step 2: run &quot;Checkerboard Calibration&quot; to get the camera intrinsic parameters</a></h2>
<p>(There is a script to draw checkerboards as SVG files:
<a href="https://github.com/strawlab/strand-braid/blob/main/strand-braid-user/scripts/draw_checkerboard_svg.py"><code>draw_checkerboard_svg.py</code></a>.)</p>
<p>In Strand Cam, there is a region called &quot;Checkerboard Calibration&quot; which allows
you to calibrate the camera intrinsic parameters. Show a checkerboard to the
camera. You must enter your the checkerboard parameters into the user interface.
For example, a standard 8x8 checkerboard would have 7x7 corners. Try to show the
checkerboard at different distances and angles. Do not forget to show the
checkerboard corners in the corners of the camera field of view. There is a
field which shows the number of checkerboard collected - this should increase as
the system detects checkerboards. When you have gathered a good set of (say, at
least 10) checkerboards, click the &quot;Perform and Save Calibration&quot; button. The
results of this calibration are saved to the directory
<code>$HOME/.config/strand-cam/camera_info</code>.</p>
<p>Repeat this for all cameras before proceeding to the next step.</p>
<h2><a class="header" href="#step-3-collect-calibration-data-and-run-multicamselfcal-mcsc" id="step-3-collect-calibration-data-and-run-multicamselfcal-mcsc">Step 3: collect calibration data and run MultiCamSelfCal (MCSC)</a></h2>
<p>To calibrate Braid, we use
<a href="https://github.com/strawlab/MultiCamSelfCal">MultiCamSelfCal</a>. This is a
software package which takes simultaneously captured images of an LED moving
through a volume to create a single calibration for all cameras.</p>
<h3><a class="header" href="#acquire-a-dataset-for-multicamselfcal" id="acquire-a-dataset-for-multicamselfcal">Acquire a dataset for MultiCamSelfCal</a></h3>
<p>Room lights should be off.</p>
<p>Synchronize your cameras and start saving data and begin to collect data by
moving a LED in the arena (try move the LED in the whole arena volume, also turn
it off and on sometimes to validate synchronization). When you are done, stop
saving.</p>
<h3><a class="header" href="#convert-braidz-file-to-flydra-mainbrain-h5-file" id="convert-braidz-file-to-flydra-mainbrain-h5-file">Convert <code>.braidz</code> file to flydra mainbrain <code>.h5</code> file</a></h3>
<blockquote>
<p>Note: from here in the document, there are many commands used from
<a href="https://github.com/strawlab/flydra">Flydra</a>. While Braid itself runs without
needing Flydra in any way, performing calibration and other data analysis
steps currently requires the use of Flydra. Specifically, the
<code>flydra_analysis</code> package is required. Please see
<a href="https://github.com/strawlab/flydra#installation">here</a> for instructions about
Flydra installation.</p>
</blockquote>
<p>By converting from <code>.braidz</code> to a Flydra mainbrain <code>.h5</code> file, you can use the
wide range of analysis programs from <a href="https://github.com/strawlab/flydra">flydra</a>.</p>
<p>For example, let's say you have the file <code>20190924_161153.braidz</code> saved by the
Braid program. We will use the script <code>convert_braidz_to_flydra_h5.py</code>
to do this conversion:</p>
<pre><code class="language-ignore">python ~/src/strand-braid/strand-braid-user/scripts/convert_braidz_to_flydra_h5.py --no-delete 20190924_161153.braidz
</code></pre>
<p>Upon success, there will be a new file saved with the suffix <code>.h5</code>. In this
case, it will be named <code>20190924_161153.braidz.h5</code>.</p>
<p>We can do the above but making use of bash variables to save typing later <code>BRAIDZ_FILE</code>.</p>
<pre><code class="language-ignore">BRAIDZ_FILE=20190924_161153.braidz
DATAFILE=&quot;$BRAIDZ_FILE.h5&quot;
python ~/src/strand-braid/strand-braid-user/scripts/convert_braidz_to_flydra_h5.py --no-delete $BRAIDZ_FILE
</code></pre>
<p>Note that this conversion requires the program <code>compute-flydra1-compat</code> (this
should be installed with Strand Camera and Braid by default and is part of the
the <code>braid-offline</code> rust crate) to be on your path if you are converting 3D
trajectories.</p>
<h3><a class="header" href="#run-multicamselfcal-on-data-collected-with-braid" id="run-multicamselfcal-on-data-collected-with-braid">Run MultiCamSelfCal on data collected with Braid</a></h3>
<p>You can collect data and calibrate similar to <a href="https://github.com/strawlab/flydra/blob/c9f20d5f8f4feb7e1fe008cf0ee67fbbc70b1ba0/docs/flydra-sphinx-docs/calibrating.md">the description for Flydra</a></p>
<p>If your mainbrain <code>.h5</code> file is in the location <code>$DATAFILE</code>, you can run the <a href="https://github.com/strawlab/MultiCamSelfCal">MultiCamSelfCal</a>
program on this data to generate a multiple camera calibration.</p>
<pre><code class="language-ignore">flydra_analysis_generate_recalibration --2d-data $DATAFILE --disable-kalman-objs $DATAFILE --undistort-intrinsics-yaml=$HOME/.config/strand-cam/camera_info  --run-mcsc --use-nth-observation=4
</code></pre>
<p>This will print various pieces of information to the console when it runs. First it will print something like this:</p>
<pre><code class="language-ignore">851 points
by camera id:
 Basler_40022057: 802
 Basler_40025037: 816
 Basler_40025042: 657
 Basler_40025383: 846
by n points:
 3: 283
 4: 568
</code></pre>
<p>This means that 851 frames were acquired in which 3 or more cameras detected exactly one point.
The contribution from each camera is listed. In this example, all cameras had between 657 and
846 points. Then, the number of points detected by exactly 3 cameras is shown (283 such frames)
and exactly 4 cameras (568 frames).</p>
<p>Important things to watch for are listed here. These may be useful, but are rather
rough guidelines to provide some orientation:</p>
<ul>
<li>
<p>No camera should have very few points, otherwise this camera will not contribute much to
the overall calibration and will likely have a bad calibration itself.</p>
</li>
<li>
<p>The number of points used should be somewhere between 300 and 1000. Fewer than 300 points
often results in poor quality calibrations. More than 1000 points results in the calibration
procedure being very slow. The <code>--use-nth-observation</code> command line argument can be used
to change the number of points used.</p>
</li>
</ul>
<p>After running successfully, the console output should look something like this:</p>
<pre><code class="language-ignore">********** After 0 iteration *******************************************
RANSAC validation step running with tolerance threshold: 10.00 ...
RANSAC: 1 samples, 811 inliers out of 811 points
RANSAC: 2 samples, 811 inliers out of 811 points
RANSAC: 2 samples, 762 inliers out of 762 points
RANSAC: 1 samples, 617 inliers out of 617 points
811 points/frames have survived validations so far
Filling of missing points is running ...
Repr. error in proj. space (no fact./fact.) is ...  0.386139 0.379033
************************************************************
Number of detected outliers:   0
About cameras (Id, 2D reprojection error, #inliers):
CamId    std       mean  #inliers
  1      0.41      0.41    762
  2      0.33      0.33    811
  3      0.49      0.41    617
  4      0.33      0.37    811
***************************************************************
**************************************************************
Refinement by using Bundle Adjustment
Repr. error in proj. space (no fact./fact./BA) is ...  0.388949 0.381359 0.358052
2D reprojection error
All points: mean  0.36 pixels, std is 0.31

finished: result in  /home/strawlab/20190924_161153.braidz.h5.recal/result
</code></pre>
<p>Important things to watch for:</p>
<ul>
<li>
<p>There should only be one iteration (numbered <code>0</code>).</p>
</li>
<li>
<p>The mean reprojection error should be low. Certainly less than
1 pixel and ideally less than 0.5 pixels as shown here.</p>
</li>
<li>
<p>The reprojection error should be low across all cameras.</p>
</li>
</ul>
<p>The above example calibration is a good one.</p>
<h3><a class="header" href="#convert-your-new-calibration-to-an-xml-file-which-can-be-used-by-braid" id="convert-your-new-calibration-to-an-xml-file-which-can-be-used-by-braid">Convert your new calibration to an XML file which can be used by Braid</a></h3>
<p>Convert this to XML:</p>
<pre><code class="language-ignore">flydra_analysis_calibration_to_xml ${DATAFILE}.recal/result &gt; new-calibration-name.xml
</code></pre>
<p>You may now use this new calibration, saved as an XML file, as the calibration
for Braid. Specify the filename of your new XML file as <code>cal_fname</code> in the
<code>[mainbrain]</code> section of your Braid configuration <code>.toml</code> file.</p>
<h3><a class="header" href="#with-the-new-calibration-perform-offline-tracking-the-data-used-to-calibrate" id="with-the-new-calibration-perform-offline-tracking-the-data-used-to-calibrate">With the new calibration, perform offline tracking the data used to calibrate.</a></h3>
<p>Now you have a working calibration, which is NOT aligned or scaled to any
coordinate system, but an (undefined) coordinate system that from MCSC code
picked. We can use this calibration to do tracking, although in general having
correct scaling is important for good tracking. The reason correct scaling is
important for good quality tracking is because Braid tracks using a dynamic
model of movement in which maneuverability is parameterized and tracking
performance is best when the actual maneuverability statistics match the
expected statistic.</p>
<p>So, using the calibration from above, perform 3D tracking of the data with:</p>
<pre><code class="language-ignore">flydra_kalmanize ${DATAFILE} -r ${DATAFILE}.recal/result
</code></pre>
<p>You can view these results with:</p>
<pre><code class="language-ignore">DATAFILE_RETRACKED=`python -c &quot;print('${DATAFILE}'[:-3])&quot;`.kalmanized.h5
flydra_analysis_plot_timeseries_2d_3d ${DATAFILE} -k ${DATAFILE_RETRACKED} --disable-kalman-smoothing
</code></pre>
<h3><a class="header" href="#align-your-new-calibration-using-a-gui" id="align-your-new-calibration-using-a-gui">Align your new calibration using a GUI</a></h3>
<p>Now we will take our existing &quot;unaligned&quot; calibration, and despite the scaling
and alignment issue, track some points so that we have 3D coordinates. We will
use these 3D coordinates to &quot;align&quot; our calibration -- to adjust its scaling,
rotation, and translation to arrive at a final calibration which outputs
coordinates in the desired frame.</p>
<p>Now, using the unaligned calibration from above, collect a dataset which
outlines the geometry of your arena or other key 3D points which we serve as
reference 3D points used to discover the correct alignment. We will use these
unaligned 3D points output from the unaligned calibration to determine an
alignment and scaling used to transform these 3D points to the correct,
&quot;aligned&quot; 3D points. These alignment parameters will be used to update the original unaligned calibration into the final aligned calibration.</p>
<p>The easiest way to acquire unaligned 3D points is to acquire a new dataset
directly by running Braid with the new unaligned calibration. Alternatively, one
can use a pre-existing 2D dataset and re-track it with <code>flydra_kalmanize</code> as
above. We will call this dataset for alignment <code>${NEW_TRACKED_DATA}</code>.</p>
<p>With this new dataset for alignment, we render the 3D tracks with a 3D model of
some pre-specified geometry in the correct coordinate frame. We then adjust the
alignment parameters by hand in a GUI. Here we align our newly tracked data in
file <code>${NEW_TRACKED_DATA}</code> against the <code>sample_bowl.xml</code> file from
<a href="https://github.com/strawlab/flydra/blob/main/flydra_analysis/flydra_analysis/a2/sample_bowl.xml">here</a>.
In this example, the <code>sample_bowl.xml</code> file outlines a circle with diameter 0.33
meters on the Z=0 plane. In this example, we tracked an LED outlining a circle
of diameter 0.33 meters and on the plane which will be Z=0 in our final
coordinate frame. Here is how to run the GUI program for running the alignment:</p>
<pre><code class="language-ignore">flydra_analysis_calibration_align_gui --stim-xml ~/src/flydra/flydra_analysis/flydra_analysis/a2/sample_bowl.xml ${NEW_TRACKED_DATA}
</code></pre>
<h3><a class="header" href="#automatic-alignment-of-calibrations" id="automatic-alignment-of-calibrations">Automatic alignment of calibrations</a></h3>
<p>As an alternative to using the GUI to perform alignment, it is possible to find
the correct alignment automatically. The flydra program
<code>flydra_analysis_align_calibration</code> does this. The major mathematical operations
are performed in the <code>estsimt</code> function in
<a href="https://github.com/strawlab/flydra/blob/main/flydra_core/flydra_core/align.py"><code>flydra_core.align</code></a>.</p>
<p>(TODO: Write an example doing this.)</p>
<h3><a class="header" href="#calibration-with-water" id="calibration-with-water">Calibration with water</a></h3>
<p>As described
<a href="braid_3d_tracking.html#tracking-in-water-with-cameras-out-of-water">here</a>, Braid
can track objects in water. To enable this, place the string
<code>&lt;water&gt;1.333&lt;/water&gt;</code> in the XML camera calibration file.</p>
<h1><a class="header" href="#remote-cameras-for-braid" id="remote-cameras-for-braid">Remote Cameras for Braid</a></h1>
<h2><a class="header" href="#what-are-remote-cameras" id="what-are-remote-cameras">What are &quot;remote cameras&quot;?</a></h2>
<p>A remote camera, in the context of Braid, can be used to connect cameras on
separate computers over the network to an instance of Braid. One or more
instances of Strand Camera can thus run on computers other than the computer on
which Braid is running.</p>
<h2><a class="header" href="#starting-a-remote-camera" id="starting-a-remote-camera">Starting a remote camera</a></h2>
<p>If a particular camera is marked by setting <code>start_backend = &quot;remote&quot;</code> in the
<code>[[cameras]]</code> section of the Braid configuration TOML file, <code>braid run</code> does not
attempt to start the camera but rather waits for a network connection from a
Braid-tuned variant of Strand Camera. Only once all cameras listed in the TOML
file have connected will Braid synchronize the cameras and allow recording of
data.</p>
<p>To start Strand Camera as a remote camera for Braid, run <code>strand-cam-pylon</code> (to
start Strand Camera) with the command line argument <code>--braid_addr &lt;URL&gt;</code>
specifying the URL for the braid HTTP address. The camera name should also be
specified on the command line, along with any other options.</p>
<p>In the following example, the Strand Camera will open the camera named
<code>Basler-12345</code> and will connect to Braid running at <code>http://127.0.0.1:44444</code>.</p>
<pre><code class="language-ignore">strand-cam-pylon --camera-name Basler-12345 --braid_addr http://127.0.0.1:44444
</code></pre>
<h1><a class="header" href="#scripting-with-python" id="scripting-with-python">Scripting with Python</a></h1>
<p>Everything in Strand Cam and Braid that can be controlled from the web browser
can also be controlled from a Python script. The general technique is to use a
Python library to connect to a running Strand Cam (or Braid) program exactly
like a web browser does it.</p>
<h2><a class="header" href="#demo-changing-tracking-settings-from-a-python-script" id="demo-changing-tracking-settings-from-a-python-script">Demo: changing tracking settings from a Python script</a></h2>
<p>TODO: describe how to use and modify the <a href="https://github.com/strawlab/strand-braid/blob/main/strand-braid-user/scripts/record-mp4-video.py"><code>record-mp4-video.py</code>
demo</a>.</p>
<h2><a class="header" href="#advanced-automating-manual-actions" id="advanced-automating-manual-actions">Advanced: automating manual actions</a></h2>
<p>TODO: describe how to use the developer tools to watch the network requests from
your browser to view HTTP POST callbacks taken on certain actions.</p>
<h2><a class="header" href="#advanced-running-strand-cam-within-python" id="advanced-running-strand-cam-within-python">Advanced: Running Strand Cam within Python</a></h2>
<p>It is also possible to run strand cam within a Python program. This allows, for
example, to analyze images from within a Python script with minimal latency. See
the
<a href="https://github.com/strawlab/strand-braid/tree/main/py-strandcam">py-strandcam</a>
directory.</p>
<h1><a class="header" href="#processing-recorded-videos-using-braid" id="processing-recorded-videos-using-braid">Processing recorded videos using Braid</a></h1>
<h2><a class="header" href="#overview" id="overview">Overview</a></h2>
<p>The <code>braid-process-video</code> program will takes video files and process them to
produce various outputs.</p>
<!--- todo: convert image to show .mp4 not .mkv -->
<p><img src="braid-process-video.png" alt="braid-process-video.png" /></p>
<p>As shown in the figure, this program takes <code>.mp4</code> (or <code>.fmf</code>) video input files
saved by Braid and a configuration file and then creates an output <code>.mp4</code> video
which stitches the input videos together. Optionally, it can also plot 2D
detections from a <code>.braidz</code> file on top of the raw video.</p>
<h2><a class="header" href="#note" id="note">Note</a></h2>
<ul>
<li>The input videos must be saved by Braid to ensure that the timestamps for each
frame in the file are correctly stored.</li>
</ul>
<h2><a class="header" href="#example-usage-1-automatic-determination-of-inputs" id="example-usage-1-automatic-determination-of-inputs">Example usage 1: Automatic determination of inputs</a></h2>
<p>If a directory contains a single <code>.braidz</code> file and one or more video files,
<code>braid-process-video</code> can automatically generate a video with default options.
In this case run it like so:</p>
<pre><code class="language-ignore">braid-process-video auto-config --input-dir /path/to/video-and-braidz-files
</code></pre>
<h2><a class="header" href="#example-usage-2-use-of-a-toml-configuration-file" id="example-usage-2-use-of-a-toml-configuration-file">Example usage 2: Use of a <code>.toml</code> configuration file</a></h2>
<p>Here is an example configuration file <code>braid-bundle-videos.toml</code>:</p>
<pre><code class="language-ignore"># The .braidz file with 2D detection data (optional).
input_braidz = &quot;20211011_163203.braidz&quot;

# This stanza specified that an output video will be made.
[[output]]
type = 'video'
filename = 'composite.mp4'

# The following sections specify video sources to use as input.
[[input_video]]
filename = 'movie20211011_163224.mp4'

[[input_video]]
filename = 'movie20211011_163228.mp4'
</code></pre>
<p>With such a configuration file, run the program like so:</p>
<pre><code class="language-ignore">braid-process-video config-toml --config-toml braid-bundle-videos.toml
</code></pre>
<h2><a class="header" href="#todo" id="todo">TODO</a></h2>
<p>There are many more options which can be configured in the <code>.toml</code> configuration
file and they should be documented.</p>
<h1><a class="header" href="#fmf-fly-movie-format---simple-uncompressed-movie-storage-format" id="fmf-fly-movie-format---simple-uncompressed-movie-storage-format">FMF (Fly Movie Format) - simple, uncompressed movie storage format</a></h1>
<p><strong>New users are recommended to use MP4 files for video rather than FMF files.</strong>
Strand Camera supports saving to MP4 files, using several different potential
encoders.</p>
<p>The primary design goals of FMF files are:</p>
<ul>
<li>Single pass, low CPU overhead writing of lossless movies for realtime streaming applications</li>
<li>Precise timestamping for correlation with other activities</li>
<li>Simple format that can be written and read from a variety of languages.</li>
</ul>
<p>These goals are achieved via using a very simple format. After an initial header
containing meta-data such as image size and color coding scheme (e.g.
monochromatic 8 bits per pixel, YUV422, etc.), repeated chunks of raw image data
and timestamp are saved. Because the raw image data from the native camera
driver is saved, no additional processing is performed. Thus, streaming of
movies from camera to disk will keep the CPU free for other tasks, but it will
require a lot of disk space. Furthermore, the disk bandwidth required is
equivalent to the camera bandwidth (unless you save only a region of the images,
or if you only save a fraction of the incoming frames).</p>
<p>The FMF file type defines raw image sequences where each image is stored exactly
in the raw data bytes as they were acquired from the camera together with with a
timestamp. There are two versions implemented, versions 1 and 3 (Version 2 was
briefly used internally and is now best forgotten). Version 1 is deprecated and
new movies should not be written in this format.</p>
<p>A <strong>Rust</strong> implementation to read and write <code>.fmf</code> files can be found in the
<a href="https://github.com/strawlab/strand-braid/tree/main/fmf"><code>github.com/strawlab/strand-braid</code>
repository</a>.</p>
<p>Documentation for the file type and reading/writing <code>.fmf</code> files in <strong>Python</strong>
can be found at the <a href="http://code.astraw.com/projects/motmot/fly-movie-format.html">documentation of
<code>motmot.FlyMovieFormat</code></a>.</p>
<p>A <strong>MATLAB</strong> implementation can be found in the
<a href="https://github.com/motmot/flymovieformat/tree/master/matlab"><code>github.com/motmot/flymovieformat</code>
repository</a>.</p>
<p>An <strong>R</strong> implementation can be found in the <a href="https://github.com/jefferis/fmfio"><code>github.com/jefferis/fmfio</code>
repository</a>.</p>
<h2><a class="header" href="#converting-movies-to-and-from-fmf-format-with-the-fmf-command-line-program" id="converting-movies-to-and-from-fmf-format-with-the-fmf-command-line-program">Converting movies to and from FMF format with the <code>fmf</code> command line program</a></h2>
<p>The <code>fmf</code> command line program from
<a href="https://github.com/strawlab/strand-braid/tree/main/fmf/fmf-cli">https://github.com/strawlab/strand-braid/tree/main/fmf/fmf-cli</a>
can be used for a variety of tasks with <code>.fmf</code> files, especially converting to
and from other formats.</p>
<p>Here is the output <code>fmf --help</code>:</p>
<pre><code class="language-ignore">strawlab@flycube10:~$
fmf 0.1.0
work with .fmf (fly movie format) files

USAGE:
    fmf &lt;SUBCOMMAND&gt;

FLAGS:
    -h, --help       Prints help information
    -V, --version    Prints version information

SUBCOMMANDS:
    export-fmf       export an fmf file
    export-jpeg      export a sequence of jpeg images
    export-mp4       export to mp4
    export-png       export a sequence of png images
    export-y4m       export to y4m (YUV4MPEG2) format
    help             Prints this message or the help of the given subcommand(s)
    import-images    import a sequence of images, converting it to an FMF file
    info             print information about an fmf file
</code></pre>
<p>See https://github.com/strawlab/strand-braid/tree/main/fmf/fmf-cli for more information.</p>
<h2><a class="header" href="#file-structure" id="file-structure">File Structure</a></h2>
<table><thead><tr><th>FMF File structure</th></tr></thead><tbody>
<tr><td>Header</td></tr>
<tr><td>Frame chunk 0</td></tr>
<tr><td>Frame chunk 1</td></tr>
<tr><td>Frame chunk 2</td></tr>
<tr><td>...</td></tr>
<tr><td>Frame chunk N</td></tr>
</tbody></table>
<p>The chunk size is specified in the header and is equal to the raw frame pixel
data size plus 8 bytes for the timestamp. Thus a 640 pixel wide, 480 pixel high
MONO8 format image would have a <code>chunksize</code> of 307208 (equal to 640 * 480 + 8).</p>
<p>Because the chunk size is constant for all frames, any chunk can be accessed by
computing its position and seeking to that location. For the same reason, the
image data within FMF files can be memory mapped.</p>
<h3><a class="header" href="#header-version-3" id="header-version-3">Header Version 3</a></h3>
<p>This is the preferred header for all new FMF files.</p>
<table><thead><tr><th>Start position</th><th>Type</th><th>Name</th><th>Description</th></tr></thead><tbody>
<tr><td>0</td><td>u32</td><td>version</td><td>Version number (3)</td></tr>
<tr><td>4</td><td>u32</td><td>lenformat</td><td>Length of the subsequent format string</td></tr>
<tr><td>8</td><td>[u8; N]</td><td>format</td><td>ASCII string of N characters containing pixel format, e.g. <code>MONO8</code> or <code>YUV422</code></td></tr>
<tr><td>8+N</td><td>u32</td><td>bpp</td><td>Bits per pixel, e.g. 8</td></tr>
<tr><td>12+N</td><td>u32</td><td>height</td><td>Number of rows of image data</td></tr>
<tr><td>16+N</td><td>u32</td><td>width</td><td>Number of columns of image data</td></tr>
<tr><td>20+N</td><td>u64</td><td>chunksize</td><td>Bytes per &quot;chunk&quot; (timestamp + frame)</td></tr>
<tr><td>28+N</td><td>u64</td><td>n_frames</td><td>Number of frame chunks (0=unknown, read file to find out)</td></tr>
</tbody></table>
<p>For the <code>format</code> field, the following pixel formats are known:</p>
<table><thead><tr><th>Format string</th><th>Description</th></tr></thead><tbody>
<tr><td><code>MONO8</code></td><td>Monochrome data, 8 bits per pixel</td></tr>
<tr><td><code>RAW8:RGGB</code></td><td>Raw Bayer mosaic data, RGGB pattern, 8 bits per pixel</td></tr>
<tr><td><code>RAW8:GBRG</code></td><td>Raw Bayer mosaic data, GBRG pattern, 8 bits per pixel</td></tr>
<tr><td><code>RAW8:GRBG</code></td><td>Raw Bayer mosaic data, GRBG pattern, 8 bits per pixel</td></tr>
<tr><td><code>RAW8:BGGR</code></td><td>Raw Bayer mosaic data, BGGR pattern, 8 bits per pixel</td></tr>
<tr><td><code>YUV422</code></td><td>Packed YUV encoded data, 16 bits per pixel</td></tr>
<tr><td><code>RGB8</code></td><td>Packed RGB encoded data, 24 bits per pixel</td></tr>
</tbody></table>
<p>This list of pixel formats is not exhaustive and other formats can be added.</p>
<h3><a class="header" href="#header-version-1" id="header-version-1">Header Version 1</a></h3>
<p> This version is deprecated and no new files with this format should be written. </p>
<p>Only supports MONO8 pixel format.</p>
<table><thead><tr><th>Start position</th><th>Type</th><th>Name</th><th>Description</th></tr></thead><tbody>
<tr><td>0</td><td>u32</td><td>version</td><td>Version number (1)</td></tr>
<tr><td>4</td><td>u32</td><td>height</td><td>Number of rows of image data</td></tr>
<tr><td>8</td><td>u32</td><td>width</td><td>Number of columns of image data</td></tr>
<tr><td>12</td><td>u64</td><td>chunksize</td><td>Bytes per &quot;chunk&quot; (timestamp + frame)</td></tr>
<tr><td>20</td><td>u64</td><td>n_frames</td><td>Number of frames (0=unknown, read file to find out)</td></tr>
</tbody></table>
<h3><a class="header" href="#frame-chunks" id="frame-chunks">Frame Chunks</a></h3>
<p>Frame chunks have an identical format in FMF v1 and v3 files. From a given
camera pixel format and size, they are constant in size and thus the Nth frame
can be accessed by seeking to <code>frame0_offset + n*chunksize</code>. The image data is
uncompressed raw image data as read directly from the camera.</p>
<table><thead><tr><th>Start position within chunk</th><th>Type</th><th>Name</th><th>Description</th></tr></thead><tbody>
<tr><td>0</td><td>f64</td><td>timestamp</td><td>Timestamp (seconds in current epoch)</td></tr>
<tr><td>8</td><td>[u8; N]</td><td>image_data</td><td>Image data</td></tr>
</tbody></table>
<h3><a class="header" href="#types-used-above" id="types-used-above">Types used above</a></h3>
<p>All numbers are little-endian (Intel standard).</p>
<table><thead><tr><th>Type</th><th>size (in bytes)</th><th>description</th></tr></thead><tbody>
<tr><td>[u8; N]</td><td>N</td><td>variable length buffer of characters</td></tr>
<tr><td>u32</td><td>4</td><td>unsigned 32 bit integer</td></tr>
<tr><td>u64</td><td>8</td><td>unsigned 64 bit integer</td></tr>
<tr><td>f64</td><td>8</td><td>64 bit floating point number</td></tr>
</tbody></table>
<h1><a class="header" href="#troubleshooting" id="troubleshooting">Troubleshooting</a></h1>
<h2><a class="header" href="#synchronization-problems" id="synchronization-problems">synchronization problems</a></h2>
<h2><a class="header" href="#any-other-problem-or-question" id="any-other-problem-or-question">any other problem or question</a></h2>
<p>Please <a href="https://github.com/strawlab/strand-braid/issues">report any issues you
face</a> or <a href="https://groups.google.com/forum/#!forum/multicams">ask any questions you
may have</a>.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        

        
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        

        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
        
        

    </body>
</html>
