use camino::{Utf8Path, Utf8PathBuf};
use clap::Parser;
use eyre::Context;
// use levenberg_marquardt::LeastSquaresProblem;
use opencv_ros_camera::{NamedIntrinsicParameters, RosCameraInfo, RosOpenCvIntrinsics};
use std::{
    collections::{BTreeMap, BTreeSet},
    io::Write,
    net::ToSocketAddrs,
};

use ads_webasm::components::{MaybeCsvData, parse_csv};
use braid_april_cal::*;

const MIN_NUM_BA_CAMS: usize = 3;
const RERUN_2499_OPEN: bool = true; // https://github.com/rerun-io/rerun/issues/2499

#[derive(Parser, Debug)]
#[command(author, version, about, long_about = None)]
pub struct Cli {
    /// CSV file with April Tags 3D fiducial coordinates.
    #[arg(long)]
    pub apriltags_3d_fiducial_coords: Utf8PathBuf,

    /// Directory containing `apriltags<date>_<time>_<cam-name>.csv` files.
    #[arg(long)]
    pub apriltags_2d_detections_dir: Utf8PathBuf,

    /// Directory containing `<cam-name>.yaml` YAML files with camera intrinsics.
    #[arg(long)]
    pub camera_info_dir: Utf8PathBuf,

    /// Directory containing `<cam-name>.png` PNG files with camera images. Only
    /// used when logging data to rerun.
    #[arg(long)]
    pub image_dir: Option<Utf8PathBuf>,

    /// Calibration XML output filename.
    #[arg(long)]
    pub output_xml: Utf8PathBuf,

    /// Perform bundle adjustment to refine the results generated by the SQPnP
    /// algorithm.
    #[arg(long)]
    bundle_adjustment: bool,

    /// Log data to rerun viewer at this socket address. (The typical address is
    /// "127.0.0.1:9876".)
    #[arg(long)]
    rerun: Option<String>,
}

fn main() -> eyre::Result<()> {
    if std::env::var_os("RUST_LOG").is_none() {
        // SAFETY: We ensure that this only happens in single-threaded code
        // because this is immediately at the start of main() and no other
        // threads have started.
        unsafe { std::env::set_var("RUST_LOG", "info") };
    }
    env_tracing_logger::init();
    let opt = Cli::parse();
    perform_calibration(
        opt.apriltags_3d_fiducial_coords,
        opt.apriltags_2d_detections_dir,
        opt.camera_info_dir,
        opt.image_dir,
        opt.output_xml,
        opt.bundle_adjustment,
        opt.rerun,
    )
}

/// Perform the calibration
///
/// - Step 1: solve PnP with prior intrinsics. Inputs: 3d world coords of april
///   tags and camera intrinsics, Output: camera extrinsics.
/// - Step 2 (optional): perform bundle adjustement. Inputs: all of the above.
///   Refines 3d world coords and camera extrinsics.
fn perform_calibration<P: AsRef<Utf8Path>>(
    apriltags_3d_fiducial_coords: P,
    apriltags_2d_detections_dir: P,
    camera_info_dir: P,
    image_dir: Option<P>,
    output_xml: P,
    bundle_adjustment: bool,
    rerun: Option<String>,
) -> eyre::Result<()> {
    let apriltags_3d_fiducial_coords = apriltags_3d_fiducial_coords.as_ref();
    let fiducial_3d_coords_buf = std::fs::read(apriltags_3d_fiducial_coords.as_std_path())?;
    let fiducial_3d_coords = parse_csv::<Fiducial3DCoords>(
        apriltags_3d_fiducial_coords.to_string(),
        &fiducial_3d_coords_buf,
    );
    let fiducial_3d_coords = match fiducial_3d_coords {
        MaybeCsvData::Valid(data) => data.rows().to_vec(),
        _ => panic!("failed parsing"),
    };

    let mut per_camera_2d: BTreeMap<String, _> = Default::default();
    let mut known_good_intrinsics: Option<BTreeMap<String, _>> = Some(Default::default());

    // These should all be the same length
    let mut observed: Vec<f64> = Vec::new();
    let mut cam_idx = Vec::new();
    let mut pt_idx = Vec::new();
    let mut labels = Vec::new();

    let mut cam_names = Vec::new();
    let mut cam_dims = Vec::new();

    let mut tag_id_to_pt_idx = BTreeMap::new();
    let mut points0 = Vec::new();
    let mut labels3d = Vec::new();
    for (ipt_idx, coord) in fiducial_3d_coords.iter().enumerate() {
        if tag_id_to_pt_idx.insert(coord.id, ipt_idx).is_some() {
            eyre::bail!(
                "multiple tags with id {} present in file \"{apriltags_3d_fiducial_coords}\"",
                coord.id,
            );
        }
        points0.push(coord.x);
        points0.push(coord.y);
        points0.push(coord.z);
        labels3d.push(format!("{}", coord.id));
    }

    let mut cams_per_id = BTreeMap::new();
    for coord in fiducial_3d_coords.iter() {
        cams_per_id.insert(coord.id, std::collections::BTreeSet::new());
    }

    let mut uvs_per_cam_per_id = BTreeMap::new();
    let mut seen_ids_without_3d = BTreeSet::new();
    let mut image_fnames = BTreeMap::new();

    // Read april tag detections for each camera.
    for entry in apriltags_2d_detections_dir.as_ref().read_dir_utf8()? {
        let entry = entry?;
        if entry.file_name().starts_with("apriltags")
            && entry.file_name().ends_with("csv")
            && entry
                .file_type()
                .ok()
                .map(|x| x.is_file())
                .unwrap_or_default()
        {
            // Load april tag detections
            let entry = entry.into_path();
            let buf = std::fs::read(entry.as_std_path())
                .with_context(|| format!("while opening file {entry}"))?;
            let icam_idx: u8 = cam_names.len().try_into().unwrap();

            let detections = parse_csv::<AprilDetection>(entry.clone().into_string(), &buf);
            let cam_name = match detections {
                MaybeCsvData::Valid(csv_data) => {
                    let datavec = csv_data.rows().to_vec();
                    let raw_buf: &[u8] = csv_data.raw_buf();
                    let cfg = get_apriltag_cfg(raw_buf).unwrap();
                    let cam_name = cfg.camera_name.clone();

                    if per_camera_2d
                        .insert(cam_name.clone(), (cfg, datavec.clone()))
                        .is_some()
                    {
                        eyre::bail!("Multiple april tag detection files for camera {cam_name}");
                    }

                    // Collect data for bundle adjustment.
                    cam_names.push(cam_name.clone());

                    // Iterate through all rows of detection data to collect all detections
                    // per marker.
                    let mut uvs_per_id = BTreeMap::new();
                    for row in datavec {
                        uvs_per_id
                            .entry(row.id as u32)
                            .or_insert_with(Vec::new)
                            .push((row.h02, row.h12)); // The (x,y) pixel coord of detection.
                    }

                    for id in uvs_per_id.keys() {
                        if let Some(xx) = cams_per_id.get_mut(id) {
                            xx.insert(icam_idx);
                        } else {
                            seen_ids_without_3d.insert(*id);
                        };
                    }

                    if uvs_per_cam_per_id.insert(icam_idx, uvs_per_id).is_some() {
                        eyre::bail!("hmm");
                    }

                    cam_name
                }
                _ => {
                    eyre::bail!("Could not parse april tag detections file \"{entry}\"");
                }
            };

            // Load intrinsic parameters
            let intrinsics_yaml_fname = camera_info_dir.as_ref().join(format!("{cam_name}.yaml"));
            let intrinsics_yaml = std::fs::read(&intrinsics_yaml_fname)?;
            let intrinsics: RosCameraInfo<f64> = serde_yaml::from_slice(&intrinsics_yaml)?;
            let named_intrinsics: NamedIntrinsicParameters<f64> = intrinsics.try_into().unwrap();

            cam_dims.push((named_intrinsics.width, named_intrinsics.height));

            // Load intrinsic parameters
            if let Some(image_dir) = image_dir.as_ref() {
                let image_fname = image_dir.as_ref().join(format!("{cam_name}.png"));
                if image_fname.exists() {
                    image_fnames.insert(icam_idx, image_fname);
                }
            }

            // Confirm camera name is consistent.
            if named_intrinsics.name != cam_name {
                eyre::bail!("YAML file has different camera name than april tag detections file");
            }

            if known_good_intrinsics
                .as_mut()
                .unwrap()
                .insert(cam_name.clone(), named_intrinsics.clone())
                .is_some()
            {
                eyre::bail!("Multiple intrinsics YAML files for camera {cam_name}");
            }
        }
    }

    if !seen_ids_without_3d.is_empty() {
        let ids = seen_ids_without_3d.iter().collect::<Vec<_>>();
        println!("The following ids were seen but have no 3d point: {ids:?}");
    }

    let mut observed_per_cam = BTreeMap::new();
    for (icam_idx, uvs_per_id) in uvs_per_cam_per_id.iter() {
        for (id, uv) in uvs_per_id.iter() {
            // calculate mean (u,v) position
            let (sumu, sumv) = uv.iter().fold((0.0, 0.0), |accum, elem| {
                (accum.0 + elem.0, accum.1 + elem.1)
            });
            let u = sumu / uv.len() as f64;
            let v = sumv / uv.len() as f64;

            observed_per_cam
                .entry(cam_names[usize::from(*icam_idx)].clone())
                .or_insert_with(BTreeMap::new)
                .insert(*id, (u, v));
        }
    }

    // If we are using Rerun and rerun does not support distortion, we eliminate
    // all distortion prior to sending to bundle-adjust. This is because
    // bundle-adjust sends data to rerun.
    let undistort_prior_to_bundle_adj = RERUN_2499_OPEN && rerun.is_some();

    if undistort_prior_to_bundle_adj {
        tracing::warn!(
            "Rerun does not currently support lens distortion. All images and \
    image coordinates will therefore be undistorted prior to sending to \
    rerun. See https://github.com/rerun-io/rerun/issues/2499."
        );
    }

    // Gather data for bundle adjustment.
    for (icam_idx, cam_name) in cam_names.iter().enumerate() {
        let intrinsics = known_good_intrinsics
            .as_ref()
            .map(|x| x.get(cam_name))
            .flatten();
        let observed_per_id = observed_per_cam.get(cam_name).unwrap();
        for (id, (u, v)) in observed_per_id.iter() {
            if let Some(cams) = cams_per_id.get(id) {
                // Only save selected data for bundle adjustment.
                if cams.len() >= MIN_NUM_BA_CAMS {
                    if undistort_prior_to_bundle_adj {
                        if let Some(intrin) = &intrinsics {
                            let dist = cam_geom::Pixels {
                                data: nalgebra::RowVector2::<f64>::new(*u as f64, *v as f64),
                            };
                            let undist = intrin.intrinsics.undistort(&dist).data;
                            observed.push(undist[(0, 0)]);
                            observed.push(undist[(0, 1)]);
                        } else {
                            eyre::bail!("cannot undistort pixels without intrinsics");
                        }
                    } else {
                        observed.push(*u);
                        observed.push(*v);
                    }

                    cam_idx.push(icam_idx.try_into().unwrap());
                    pt_idx.push(tag_id_to_pt_idx[id]);
                    labels.push(format!("{id}"));
                }
            }
        }
    }

    let rec = if let Some(socket_addr_str) = rerun {
        let mut addrs_iter = socket_addr_str.to_socket_addrs()?;
        let socket_addr = addrs_iter.next().unwrap();
        tracing::info!("Streaming data to rerun at {socket_addr}");
        let rec = re_sdk::RecordingStreamBuilder::new(env!["CARGO_PKG_NAME"])
            .connect_tcp_opts(socket_addr, None)?;

        // Log 2D images to rerun
        for (icam_idx, cam_fname) in image_fnames.iter() {
            let cam_name = cam_names[usize::from(*icam_idx)].as_str();
            let ent_path = format!("/world/camera/{cam_name}/raw");
            if RERUN_2499_OPEN {
                let intrinsics = known_good_intrinsics
                    .as_ref()
                    .map(|x| x.get(cam_name))
                    .flatten();
                if let Some(intrinsics) = intrinsics {
                    let undist_cache = undistort_image::UndistortionCache::new(
                        &intrinsics.intrinsics,
                        intrinsics.width,
                        intrinsics.height,
                    )?;

                    use basic_frame::DynamicFrame;

                    let image = image::open(&cam_fname)?;
                    let rgb8 = convert_image::image_to_rgb8(image).unwrap();
                    let decoded = DynamicFrame::from(rgb8);
                    let undistorted = undistort_image::undistort_image(decoded, &undist_cache)?;
                    let opts = convert_image::EncoderOptions::Png;
                    let png_buf = basic_frame::match_all_dynamic_fmts!(
                        &undistorted,
                        x,
                        convert_image::frame_to_encoded_buffer(x, opts)
                    )?;
                    let im = re_types::archetypes::EncodedImage::from_file_contents(png_buf);
                    rec.log_static(ent_path, &im)?;
                } else {
                    eyre::bail!("cannot undistort image because no intrinsics specified");
                }
            } else {
                let im = to_rr_image(cam_fname)?;
                rec.log_static(ent_path, &im)?;
            }
        }

        const CAMERA_BASE_PATH: &str = "world/camera";
        const DETECT_NAME: &str = "detect";

        // Log 2D observed points to rerun
        for (cam_name, observed_per_id) in observed_per_cam.iter() {
            let mut xy: Vec<(f32, f32)> = vec![];
            let mut labels = vec![];
            for (id, uv) in observed_per_id.iter() {
                if RERUN_2499_OPEN {
                    let intrinsics = known_good_intrinsics
                        .as_ref()
                        .map(|x| x.get(cam_name))
                        .flatten();
                    if let Some(i) = intrinsics {
                        let distorted =
                            cam_geom::Pixels::new(nalgebra::Vector2::new(uv.0, uv.1).transpose());
                        let uvp = i.intrinsics.undistort(&distorted).data;
                        xy.push((uvp[(0, 0)] as f32, uvp[(0, 1)] as f32));
                    } else {
                        eyre::bail!(
                            "cannot undistort image points because no intrinsics specified"
                        );
                    }
                } else {
                    xy.push((uv.0 as f32, uv.1 as f32));
                }
                labels.push(format!("{id}"));
            }
            let path_base = format!("{CAMERA_BASE_PATH}/{cam_name}/raw");
            let ent_path = format!("{path_base}/{DETECT_NAME}");
            rec.log_static(
                ent_path.as_str(),
                &re_types::archetypes::Points2D::new(&xy).with_labels(labels),
            )
            .unwrap();
        }

        Some(rec)
    } else {
        None
    };

    let src_data = CalData {
        fiducial_3d_coords: fiducial_3d_coords.clone(),
        per_camera_2d,
        known_good_intrinsics,
    };

    let cal_result = do_calibrate_system(&src_data)?;

    // Initialize bundle_adj::BundleAdjuster so that we draw to rerun if requested.
    let mut cams0 = Vec::new();
    for name in cam_names.iter() {
        let cam = cal_result.cam_system.cam_by_name(name).unwrap();

        let cam = if undistort_prior_to_bundle_adj {
            let inner = cam.linearize_to_cam_geom();
            let intrinsics: RosOpenCvIntrinsics<f64> = inner.intrinsics().clone().into();
            cam_geom::Camera::new(intrinsics, inner.extrinsics().clone())
        } else {
            cam.as_ref().clone()
        };
        cams0.push(cam);
    }

    let model_type = bundle_adj::ModelType::FxFyExtrinsicsOnly;
    // Reshape observations to 2xN matrix.
    let observed = nalgebra::Matrix2xX::<f64>::from_column_slice(&observed);
    assert_eq!(observed.ncols(), cam_idx.len());
    assert_eq!(pt_idx.len(), cam_idx.len());
    let points0 = nalgebra::Matrix3xX::<f64>::from_column_slice(&points0);

    println!("Given 3d point locations:");

    show_points(&points0, &labels3d[..]);

    println!("Results from SQPnP algorithm using prior intrinsics:");

    show_cams(&cam_names, &cal_result.cam_system)?;

    show_reproj_matrix(
        &cam_names,
        &cal_result.cam_system,
        &observed_per_cam,
        &tag_id_to_pt_idx,
        &points0,
    )?;

    let ba = bundle_adj::BundleAdjuster::new(
        observed,
        cam_idx,
        pt_idx,
        cam_names.clone(),
        cam_dims,
        cams0,
        points0.clone(),
        labels3d,
        model_type,
        rec,
    )?;

    let multi_cam_system = if !bundle_adjustment {
        flydra_mvg::FlydraMultiCameraSystem::from_system(cal_result.cam_system.clone(), None)
    } else {
        // perform bundle adjustment
        // let residuals_pre = ba.residuals().unwrap();

        // An idea to consider is reconstructing the 3D location of fiducial
        // markers with no given location but using that in the bundle
        // adjustment.

        let (ba, report) = levenberg_marquardt::LevenbergMarquardt::new()
            .with_stepbound(0.001)
            .minimize(ba);
        // println!("{model_type:?} {report:?}");
        if !report.termination.was_successful() {
            eyre::bail!("Bundle adjustment did not succeed.");
        };
        // let residuals_post = ba.residuals().unwrap();
        // println!(
        //     "pre: {}, post: {}",
        //     residuals_pre.abs().row_sum()[(0, 0)],
        //     residuals_post.abs().row_sum()[(0, 0)]
        // );

        let mut cams_by_name = std::collections::BTreeMap::new();

        for (name, ba_cam) in cam_names.iter().zip(ba.cams().iter()) {
            let old_cam = cal_result.cam_system.cam_by_name(name).unwrap();
            let e = ba_cam.extrinsics().clone();
            let mut i = ba_cam.intrinsics().clone();
            if undistort_prior_to_bundle_adj {
                // use original distortion
                i.distortion = old_cam.intrinsics().distortion.clone();
            }
            let cam = mvg::Camera::new(old_cam.width(), old_cam.height(), e, i)?;
            cams_by_name.insert(name.clone(), cam);
        }
        let ba_system = flydra_mvg::FlydraMultiCameraSystem::new(cams_by_name, None);
        println!("Results after refinement with bundle adjustment model \"{model_type:?}\":");

        show_points(ba.points(), ba.labels3d());
        show_cams(&cam_names, ba_system.system())?;
        show_reproj_matrix(
            &cam_names,
            ba_system.system(),
            &observed_per_cam,
            &tag_id_to_pt_idx,
            ba.points(),
        )?;
        ba_system
    };

    let mut xml_buf: Vec<u8> = Vec::new();
    multi_cam_system
        .to_flydra_xml(&mut xml_buf)
        .expect("to_flydra_xml");

    let output_xml = output_xml.as_ref();
    let mut fd = std::fs::File::create_new(output_xml)
        .with_context(|| format!("While creating output xml file \"{output_xml}\""))?;
    fd.write_all(&xml_buf)?;
    Ok(())
}

fn show_points(points: &nalgebra::Matrix3xX<f64>, labels3d: &[String]) {
    println!(" 3d point locations:");
    println!("     id        x       y       z");
    for i in 0..points.ncols() {
        let label = &labels3d[i];
        let pt = points.column(i);
        println!("  {label:>5}: {:7.3} {:7.3} {:7.3}", pt.x, pt.y, pt.z);
    }
}

fn show_cams(cam_names: &[String], system: &mvg::MultiCameraSystem<f64>) -> eyre::Result<()> {
    println!(" Camera parameters:          t_x      t_y      t_z      r_x      r_y      r_z");
    for cam_name in cam_names.iter() {
        let cam = system.cam_by_name(cam_name).unwrap();
        let cc = cam.extrinsics().camcenter();
        let (x, y, z) = (cc.x, cc.y, cc.z);
        let rot = cam.extrinsics().pose().rotation.scaled_axis();
        let (rx, ry, rz) = (rot.x, rot.y, rot.z);
        println!(" {cam_name:>20}:  {x:8.3} {y:8.3} {z:8.3} {rx:8.3} {ry:8.3} {rz:8.3}");
    }
    Ok(())
}

fn show_reproj_matrix(
    cam_names: &[String],
    system: &mvg::MultiCameraSystem<f64>,
    observed_per_cam: &BTreeMap<String, BTreeMap<u32, (f64, f64)>>,
    tag_id_to_pt_idx: &BTreeMap<u32, usize>,
    points: &nalgebra::Matrix3xX<f64>,
) -> eyre::Result<()> {
    println!(" Reprojection distance:");
    {
        let mut bits = vec!["      id".to_string()];
        for cam_name in cam_names.iter() {
            let last = if cam_name.len() >= 7 {
                let end = cam_name.len();
                let last = cam_name[end - 6..end].to_string();
                format!("â€¦{last}")
            } else {
                cam_name.clone()
            };
            bits.push(format!("{last:>7}"));
        }
        bits.push(format!("{:>7}", "mean"));
        let joined = bits.join(" ");
        let space = " ".repeat((joined.len() - 6) / 2);
        println!("{}Camera{}", space, space);
        println!("{}", joined);
    }
    let mut dists: BTreeMap<_, Vec<_>> = Default::default();
    for (id, ipt_idx) in tag_id_to_pt_idx.iter() {
        let mut bits = vec![format!("  {id:>6}")];
        let pt3d = points.column(*ipt_idx);
        let pts = cam_geom::Points::new(pt3d.transpose());

        let mut id_dists = vec![];
        for cam_name in cam_names.iter() {
            let cam = system.cam_by_name(cam_name).unwrap();
            let pt2d_expected = cam.as_ref().world_to_pixel(&pts).data.transpose();
            if let Some(uv) = observed_per_cam.get(cam_name).unwrap().get(id) {
                let pt2d_observed = nalgebra::Vector2::new(uv.0, uv.1);
                let dist = (pt2d_observed - pt2d_expected).norm();
                dists.entry(cam_name).or_default().push(dist);
                id_dists.push(dist);
                bits.push(format!("{dist:7.2}"));
            } else {
                bits.push(format!("     - "));
            }
        }
        let mean_id = id_dists.iter().sum::<f64>() / id_dists.len() as f64;
        bits.push(format!("{mean_id:7.2}"));
        println!("{}", bits.join(" "));
    }
    {
        let mut bits = vec!["    mean".to_string()];
        let mut all_dist = vec![];
        for cam_name in cam_names.iter() {
            if let Some(dists) = dists.get(cam_name) {
                let mean_dist = dists.iter().sum::<f64>() / dists.len() as f64;
                bits.push(format!("{mean_dist:7.2}"));
                all_dist.extend(dists);
            } else {
                bits.push(format!("     - "));
            }
        }
        let mean_dist = all_dist.iter().sum::<f64>() / all_dist.len() as f64;
        bits.push(format!("{mean_dist:7.2}"));
        println!("{}", bits.join(" "));
    }
    Ok(())
}

fn to_rr_image<P: AsRef<Utf8Path>>(fname: P) -> eyre::Result<re_types::archetypes::EncodedImage> {
    let contents = std::fs::read(fname.as_ref())?;
    Ok(re_types::archetypes::EncodedImage::from_file_contents(
        contents,
    ))
}
