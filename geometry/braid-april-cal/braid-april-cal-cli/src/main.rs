use braid_mvg::DistortedPixel;
use camino::{Utf8Path, Utf8PathBuf};
use clap::Parser;
use eyre::Context;
use nalgebra::Point2;
// use levenberg_marquardt::LeastSquaresProblem;
use opencv_ros_camera::{NamedIntrinsicParameters, RosCameraInfo, RosOpenCvIntrinsics};
use std::{
    collections::{BTreeMap, BTreeSet},
    io::Write,
    net::ToSocketAddrs,
};
use strand_dynamic_frame::DynamicFrameOwned;

use ads_webasm::components::{MaybeCsvData, parse_csv};
use braid_april_cal::*;
use bundle_adj::RR_CAM_BASE_PATH;

const RERUN_2499_OPEN: bool = true; // https://github.com/rerun-io/rerun/issues/2499

const DETECT_NAME: &str = "detect";

#[derive(Parser, Debug, Default)]
#[command(author, version, about, long_about = None)]
struct Cli {
    /// CSV file with April Tags 3D fiducial coordinates.
    #[arg(long)]
    apriltags_3d_fiducial_coords: Utf8PathBuf,

    /// Directory containing `apriltags<date>_<time>_<cam-name>.csv` files.
    #[arg(long)]
    apriltags_2d_detections_dir: Utf8PathBuf,

    /// Directory containing `<cam-name>.yaml` YAML files with camera intrinsics.
    #[arg(long)]
    intrinsics_yaml_dir: Utf8PathBuf,

    /// Directory containing `<cam-name>.png` PNG files with camera images. Only
    /// used when logging data to rerun.
    #[arg(long)]
    image_dir: Option<Utf8PathBuf>,

    /// Calibration XML output filename.
    #[arg(long)]
    output_xml: Utf8PathBuf,

    /// Triangulate 3D point locations of detected points with 2 or more camera
    /// views but for which no 3D location given.
    #[arg(long)]
    do_new_triangulation: bool,

    /// Perform bundle adjustment to refine the results generated by the SQPnP
    /// algorithm.
    #[arg(long)]
    bundle_adjustment: bool,

    /// If performing bundle adjustment, what is the minimum number of cameras viewing a 3D point to include that point in the bundle adjustment calculation.
    #[arg(long, default_value_t = 1)]
    bundle_adjustment_min_cams_per_point: usize,

    /// If performing bundle adjustment, specify the model type.
    #[arg(long, value_enum, default_value_t)]
    bundle_adjustment_model_type: bundle_adj::ModelType,

    /// Log data to rerun viewer at this socket address. (The typical address is
    /// "127.0.0.1:9876".) DEPRECATED. Use rerun_url instead.
    #[arg(long, hide = true)]
    rerun: Option<String>,

    /// Log data to rerun viewer at this URL. (A typical url is
    /// "rerun+http://127.0.0.1:9876/proxy\".)
    #[arg(long)]
    rerun_url: Option<String>,

    /// Force rerun to show original, distorted camera coordinates. Because
    /// Rerun does not currently support distorted camera models this option
    /// disables use of several rerun features.
    #[arg(long)]
    force_rerun_distorted: bool,
}

fn main() -> eyre::Result<()> {
    if std::env::var_os("RUST_LOG").is_none() {
        // SAFETY: We ensure that this only happens in single-threaded code
        // because this is immediately at the start of main() and no other
        // threads have started.
        unsafe { std::env::set_var("RUST_LOG", "info") };
    }
    env_tracing_logger::init();
    let opt = Cli::parse();
    perform_calibration(opt)
}

struct LineBuf {
    buf: Vec<String>,
}

impl LineBuf {
    fn xml_comment_buf(self) -> eyre::Result<Vec<u8>> {
        let mut result: Vec<u8> = Vec::new();
        result.extend_from_slice(b"<!--\n");
        for line in self.buf.into_iter() {
            if line.contains("-->") {
                eyre::bail!("cannot contain xml comment");
            }
            result.extend(line.into_bytes());
            result.push(b'\n');
        }
        result.extend_from_slice(b"-->\n");
        Ok(result)
    }
    fn push(&mut self, line: String) {
        println!("{}", line);
        self.buf.push(line);
    }
}

impl Default for LineBuf {
    fn default() -> Self {
        Self {
            buf: Default::default(),
        }
    }
}

/// Perform the calibration
///
/// - Step 1: solve PnP with prior intrinsics. Inputs: 3d world coords of april
///   tags and camera intrinsics, Output: camera extrinsics.
/// - Step 2 (optional): perform bundle adjustement. Inputs: all of the above.
///   Refines 3d world coords and camera extrinsics.
fn perform_calibration(cli: Cli) -> eyre::Result<()> {
    let Cli {
        apriltags_3d_fiducial_coords,
        apriltags_2d_detections_dir,
        intrinsics_yaml_dir,
        image_dir,
        output_xml,
        bundle_adjustment,
        rerun,
        mut rerun_url,
        bundle_adjustment_min_cams_per_point,
        do_new_triangulation,
        bundle_adjustment_model_type,
        force_rerun_distorted,
    } = cli;

    let fiducial_3d_coords_buf = std::fs::read(apriltags_3d_fiducial_coords.as_std_path())
        .with_context(|| {
            format!("Opening apriltags_3d_fiducial_coords file \"{apriltags_3d_fiducial_coords}\"")
        })?;
    let fiducial_3d_coords = parse_csv::<Fiducial3DCoords>(
        apriltags_3d_fiducial_coords.to_string(),
        &fiducial_3d_coords_buf,
    );
    let fiducial_3d_coords = match fiducial_3d_coords {
        MaybeCsvData::Valid(data) => data.rows().to_vec(),
        _ => {
            eyre::bail!(
                "Failed to parse 3D fiducial coords from file \"{apriltags_3d_fiducial_coords}\"."
            );
        }
    };

    let mut per_camera_2d: BTreeMap<String, _> = Default::default();
    let mut known_good_intrinsics: Option<BTreeMap<String, _>> = Some(Default::default());

    // These should all be the same length
    let mut observed: Vec<f64> = Vec::new();
    let mut cam_idx = Vec::new();
    let mut pt_idx = Vec::new();
    let mut labels = Vec::new();

    let mut cam_names = Vec::new();
    let mut cam_dims = Vec::new();

    let mut tag_id_to_pt_idx = BTreeMap::new();
    let mut points0 = Vec::new();
    let mut labels3d = Vec::new();
    let mut ids3d = Vec::new();
    for (ipt_idx, coord) in fiducial_3d_coords.iter().enumerate() {
        if tag_id_to_pt_idx.insert(coord.id, ipt_idx).is_some() {
            eyre::bail!(
                "multiple tags with id {} present in file \"{apriltags_3d_fiducial_coords}\"",
                coord.id,
            );
        }
        points0.push(coord.x);
        points0.push(coord.y);
        points0.push(coord.z);
        ids3d.push(coord.id);
        labels3d.push(format!("{}", coord.id));
    }

    let mut cams_per_id = BTreeMap::new();
    for coord in fiducial_3d_coords.iter() {
        cams_per_id.insert(coord.id, std::collections::BTreeSet::new());
    }

    let mut uvs_per_cam_per_id = BTreeMap::new();
    let mut seen_ids_without_3d = BTreeSet::new();
    let mut image_fnames = BTreeMap::new();

    // Read april tag detections for each camera.
    for entry in apriltags_2d_detections_dir
        .read_dir_utf8()
        .with_context(|| {
            format!(
                "Opening apriltags_2d_detections_dir directory \"{apriltags_2d_detections_dir}\""
            )
        })?
    {
        let entry = entry?;
        if (entry.file_name().starts_with("apriltags")
            || entry.file_name().ends_with(".apriltag.csv"))
            && entry.file_name().ends_with(".csv")
            && entry
                .file_type()
                .ok()
                .map(|x| x.is_file())
                .unwrap_or_default()
        {
            // Load april tag detections
            let entry = entry.into_path();
            let buf = std::fs::read(entry.as_std_path())
                .with_context(|| format!("while opening file {entry}"))?;
            let icam_idx: u8 = cam_names.len().try_into().unwrap();

            use braid_apriltag_types::AprilTagCoords2D;
            let detections = parse_csv::<AprilTagCoords2D>(entry.clone().into_string(), &buf);
            let cam_name = match detections {
                MaybeCsvData::Valid(csv_data) => {
                    let datavec = csv_data.rows().to_vec();
                    let raw_buf: &[u8] = csv_data.raw_buf();
                    let cfg = get_apriltag_cfg(raw_buf)
                        .with_context(|| format!("When reading contents of file {entry}"))?;
                    let cam_name = cfg.camera_name.clone();

                    if per_camera_2d
                        .insert(cam_name.clone(), (cfg, datavec.clone()))
                        .is_some()
                    {
                        eyre::bail!("Multiple april tag detection files for camera {cam_name}");
                    }

                    // Collect data for bundle adjustment.
                    cam_names.push(cam_name.clone());

                    // Iterate through all rows of detection data to collect all detections
                    // per marker.
                    let mut uvs_per_id = BTreeMap::new();
                    for row in datavec {
                        if row.hamming != 0 {
                            continue;
                        }
                        uvs_per_id
                            .entry(row.id as u32)
                            .or_insert_with(Vec::new)
                            .push((row.x, row.y)); // The (x,y) pixel coord of detection.
                    }

                    for id in uvs_per_id.keys() {
                        if let Some(xx) = cams_per_id.get_mut(id) {
                            xx.insert(icam_idx);
                        } else {
                            seen_ids_without_3d.insert(*id);
                        };
                    }

                    if uvs_per_cam_per_id.insert(icam_idx, uvs_per_id).is_some() {
                        eyre::bail!("hmm");
                    }

                    cam_name
                }
                _ => {
                    eyre::bail!("Could not parse april tag detections file \"{entry}\"");
                }
            };

            // Load intrinsic parameters
            let intrinsics_yaml_fname = intrinsics_yaml_dir.join(format!("{cam_name}.yaml"));
            let intrinsics_yaml = std::fs::read(&intrinsics_yaml_fname).with_context(|| {
                format!("When opening intrinsics_yaml_fname \"{intrinsics_yaml_fname}\"")
            })?;
            let intrinsics: RosCameraInfo<f64> = serde_yaml::from_slice(&intrinsics_yaml)?;
            let named_intrinsics: NamedIntrinsicParameters<f64> = intrinsics.try_into().unwrap();

            cam_dims.push((named_intrinsics.width, named_intrinsics.height));

            // Load intrinsic parameters
            if let Some(image_dir) = image_dir.as_ref() {
                let image_fname = image_dir.join(format!("{cam_name}.png"));
                if image_fname.exists() {
                    image_fnames.insert(icam_idx, image_fname);
                }
            }

            if known_good_intrinsics
                .as_mut()
                .unwrap()
                .insert(cam_name.clone(), named_intrinsics.clone())
                .is_some()
            {
                eyre::bail!("Multiple intrinsics YAML files for camera {cam_name}");
            }
        }
    }

    if per_camera_2d.is_empty() {
        eyre::bail!(
            "No April Tag detections loaded from directory \"{apriltags_2d_detections_dir}\"."
        );
    }
    let mut lines = LineBuf::default();

    lines.push(format!(
        "Results from \"{}\", run at {}.",
        env!["CARGO_PKG_NAME"],
        chrono::Local::now()
    ));

    if !seen_ids_without_3d.is_empty() {
        let ids = seen_ids_without_3d.iter().collect::<Vec<_>>();
        lines.push(format!(
            "The following ids were seen but have no 3d point: {ids:?}"
        ));
    }

    let observed_per_cam = {
        let mut observed_per_cam = BTreeMap::new();
        for (icam_idx, uvs_per_id) in uvs_per_cam_per_id.iter() {
            for (id, uv) in uvs_per_id.iter() {
                // calculate mean (u,v) position
                let (sumu, sumv) = uv.iter().fold((0.0, 0.0), |accum, elem| {
                    (accum.0 + elem.0, accum.1 + elem.1)
                });
                let u = sumu / uv.len() as f64;
                let v = sumv / uv.len() as f64;

                let cam_name = &cam_names[usize::from(*icam_idx)];
                tracing::debug!("Camera {cam_name}: id {id}, uv: ({u:.1},{v:.1})");
                observed_per_cam
                    .entry(cam_name.clone())
                    .or_insert_with(BTreeMap::new)
                    .insert(*id, (u, v));
            }
        }
        observed_per_cam
    };

    let allow_rerun_undistortion = !force_rerun_distorted && RERUN_2499_OPEN;

    // If we are using Rerun and rerun does not support distortion, we eliminate
    // all distortion prior to sending to bundle-adjust. This is because
    // bundle-adjust sends data to rerun.
    let undistort_prior_to_bundle_adj = allow_rerun_undistortion && rerun.is_some();

    if undistort_prior_to_bundle_adj {
        tracing::warn!(
            "Rerun does not currently support lens distortion. All images and \
    image coordinates will therefore be undistorted prior to sending to \
    rerun. See https://github.com/rerun-io/rerun/issues/2499."
        );
    }

    // Gather data for new triangulation
    let mut for_triangulation = BTreeMap::<u32, Vec<_>>::new();
    for (cam_name, observed_per_id) in observed_per_cam.iter() {
        for (id, (u, v)) in observed_per_id.iter() {
            for_triangulation
                .entry(*id)
                .or_insert_with(|| Vec::new())
                .push((cam_name, u, v));
        }
    }

    // Gather data for bundle adjustment
    for (icam_idx, cam_name) in cam_names.iter().enumerate() {
        let intrinsics = known_good_intrinsics
            .as_ref()
            .map(|x| x.get(cam_name))
            .flatten();
        for (id, (u, v)) in observed_per_cam.get(cam_name).unwrap().iter() {
            if let Some(cams) = cams_per_id.get(id) {
                // Only save selected data for bundle adjustment.
                if cams.len() >= bundle_adjustment_min_cams_per_point {
                    if undistort_prior_to_bundle_adj {
                        if let Some(intrin) = &intrinsics {
                            let dist = cam_geom::Pixels {
                                data: nalgebra::RowVector2::<f64>::new(*u as f64, *v as f64),
                            };
                            let undist = intrin.intrinsics.undistort(&dist).data;
                            observed.push(undist[(0, 0)]);
                            observed.push(undist[(0, 1)]);
                        } else {
                            eyre::bail!("cannot undistort pixels without intrinsics");
                        }
                    } else {
                        observed.push(*u);
                        observed.push(*v);
                    }

                    cam_idx.push(icam_idx.try_into().unwrap());
                    pt_idx.push(tag_id_to_pt_idx[id]);
                    labels.push(format!("{id}"));
                }
            }
        }
    }

    if let Some(socket_addr_str) = rerun {
        tracing::warn!("'--rerun' CLI argument is deprecated in favor of '--rerun-url'.");
        if rerun_url.is_some() {
            eyre::bail!("Cannot set both rerun and rerun_url CLI args.");
        }
        let mut addrs_iter = socket_addr_str.to_socket_addrs()?;
        let socket_addr = addrs_iter.next().unwrap();
        rerun_url = Some(format!("rerun+http://{socket_addr}/proxy"));
    };

    let rec = if let Some(rerun_url) = rerun_url {
        tracing::info!("Streaming data to rerun at {rerun_url}");
        let rec = re_sdk::RecordingStreamBuilder::new(env!["CARGO_PKG_NAME"])
            .connect_grpc_opts(rerun_url)?;

        // Log 2D images to rerun
        for (icam_idx, cam_fname) in image_fnames.iter() {
            let cam_name = cam_names[usize::from(*icam_idx)].as_str();
            let ent_path = format!("{RR_CAM_BASE_PATH}/{cam_name}/raw");
            if allow_rerun_undistortion {
                let intrinsics = known_good_intrinsics
                    .as_ref()
                    .map(|x| x.get(cam_name))
                    .flatten();
                if let Some(intrinsics) = intrinsics {
                    let undist_cache = undistort_image::UndistortionCache::new(
                        &intrinsics.intrinsics,
                        intrinsics.width,
                        intrinsics.height,
                    )?;

                    let image = image::open(&cam_fname)?;
                    let rgb8 = convert_image::image_to_rgb8(image).unwrap();
                    let decoded = DynamicFrameOwned::from_static(rgb8);
                    let undistorted =
                        undistort_image::undistort_image(decoded.borrow(), &undist_cache)?;
                    let opts = convert_image::EncoderOptions::Png;
                    let png_buf = undistorted.borrow().to_encoded_buffer(opts)?;
                    let im = re_types::archetypes::EncodedImage::from_file_contents(png_buf);
                    rec.log_static(ent_path, &im)?;
                } else {
                    eyre::bail!("cannot undistort image because no intrinsics specified");
                }
            } else {
                let im = to_rr_image(cam_fname)?;
                rec.log_static(ent_path, &im)?;
            }
        }

        // Log 2D observed points to rerun
        for (cam_name, observed_per_id_this_cam) in observed_per_cam.iter() {
            let mut xy: Vec<(f32, f32)> = vec![];
            let mut labels = vec![];
            for (id, uv) in observed_per_id_this_cam.iter() {
                if allow_rerun_undistortion {
                    let intrinsics = known_good_intrinsics
                        .as_ref()
                        .map(|x| x.get(cam_name))
                        .flatten();
                    if let Some(i) = intrinsics {
                        let distorted =
                            cam_geom::Pixels::new(nalgebra::Vector2::new(uv.0, uv.1).transpose());
                        let uvp = i.intrinsics.undistort(&distorted).data;
                        xy.push((uvp[(0, 0)] as f32, uvp[(0, 1)] as f32));
                    } else {
                        eyre::bail!(
                            "cannot undistort image points because no intrinsics specified"
                        );
                    }
                } else {
                    xy.push((uv.0 as f32, uv.1 as f32));
                }
                labels.push(format!("{id}"));
            }
            let path_base = format!("{RR_CAM_BASE_PATH}/{cam_name}/raw");
            let ent_path = format!("{path_base}/{DETECT_NAME}");
            rec.log_static(
                ent_path.as_str(),
                &re_types::archetypes::Points2D::new(&xy).with_labels(labels),
            )
            .unwrap();
        }

        Some(rec)
    } else {
        None
    };

    if let Some(rec) = &rec {
        // Log 3D points.
        let pts: Vec<[f32; 3]> = fiducial_3d_coords
            .iter()
            .map(|v| [v.x as f32, v.y as f32, v.z as f32])
            .collect();
        rec.log(
            "/",
            &re_types::archetypes::Points3D::new(&pts).with_labels(labels3d.clone()),
        )
        .unwrap();
    }

    let src_data = CalData {
        fiducial_3d_coords: fiducial_3d_coords.clone(),
        per_camera_2d,
        known_good_intrinsics,
    };

    // Run SQPnP algorithm
    let cal_result = match run_sqpnp_or_dlt(&src_data) {
        Ok(cal_result) => cal_result,
        Err(err) => {
            eyre::bail!("got error {err}");
        }
    };

    if do_new_triangulation {
        let recon =
            flydra_mvg::FlydraMultiCameraSystem::from_system(cal_result.cam_system.clone(), None);

        let mut ids3d_new = Vec::new();
        let mut points_new = Vec::new();
        for (id, entries) in for_triangulation.iter() {
            let mut points = Vec::with_capacity(entries.len());
            for (cam_name, u, v) in entries.iter() {
                points.push((
                    (*cam_name).clone(),
                    DistortedPixel {
                        coords: Point2::new(**u, **v),
                    },
                ));
            }
            if points.len() >= 2 {
                let xyz = recon.find3d_distorted(&points)?;
                ids3d_new.push(*id);
                let wc = xyz.point().coords;
                points_new.push(wc.x);
                points_new.push(wc.y);
                points_new.push(wc.z);
            }
        }
        lines.push(format!("Newly triangulated 3d point locations:"));
        let points_new = nalgebra::Matrix3xX::<f64>::from_column_slice(&points_new);
        show_points_csv(&points_new, &ids3d_new[..], &mut lines);
    }

    lines.push(format!("Given 3d point locations:"));
    let points0 = nalgebra::Matrix3xX::<f64>::from_column_slice(&points0);
    show_points(&points0, &ids3d[..], &mut lines);

    lines.push(format!(
        "Results from SQPnP algorithm using prior intrinsics:"
    ));

    show_cams(&cam_names, &cal_result.cam_system, &mut lines)?;

    show_reproj_matrix(
        &cam_names,
        &cal_result.cam_system,
        &observed_per_cam,
        &tag_id_to_pt_idx,
        &points0,
        &mut lines,
    )?;

    let model_type = bundle_adjustment_model_type;
    let ba = {
        // Initialize structures for bundle adjustment. We initialize
        // `bundle_adj::BundleAdjuster`, even if we don't want to run bundle
        // adjustment because it draws our 3D cameras in rerun.
        let mut cams0 = Vec::new();
        for name in cam_names.iter() {
            let cam = cal_result.cam_system.cam_by_name(name).unwrap();

            let cam = if undistort_prior_to_bundle_adj {
                let inner = cam.linearize_to_cam_geom();
                let intrinsics: RosOpenCvIntrinsics<f64> = inner.intrinsics().clone().into();
                cam_geom::Camera::new(intrinsics, inner.extrinsics().clone())
            } else {
                cam.as_ref().clone()
            };
            cams0.push(cam);
        }
        // Reshape observations to 2xN matrix.
        let observed = nalgebra::Matrix2xX::<f64>::from_column_slice(&observed);
        assert_eq!(observed.ncols(), cam_idx.len());
        assert_eq!(pt_idx.len(), cam_idx.len());

        bundle_adj::BundleAdjuster::new(
            observed,
            cam_idx,
            pt_idx,
            cam_names.clone(),
            cam_dims,
            cams0,
            points0.clone(),
            labels3d,
            model_type,
            rec,
            force_rerun_distorted,
        )?
    };

    let multi_cam_system = if !bundle_adjustment {
        flydra_mvg::FlydraMultiCameraSystem::from_system(cal_result.cam_system.clone(), None)
    } else {
        // Perform bundle adjustment.
        let residuals_pre = levenberg_marquardt::LeastSquaresProblem::residuals(&ba).unwrap();
        tracing::debug!("residuals prior to bundle adjustment: {residuals_pre}");

        // An idea to consider is reconstructing the 3D location of fiducial
        // markers with no given location but using that in the bundle
        // adjustment.

        let (ba, report) = levenberg_marquardt::LevenbergMarquardt::new()
            .with_stepbound(0.001)
            .minimize(ba);
        if !report.termination.was_successful() {
            eyre::bail!("Bundle adjustment did not succeed.");
        };

        let residuals_post = levenberg_marquardt::LeastSquaresProblem::residuals(&ba).unwrap();
        tracing::debug!("residuals after bundle adjustment: {residuals_post}");
        tracing::debug!(
            "residual abs sum before BA : {:.2}, after BA: {:.2}",
            residuals_pre.abs().row_sum()[(0, 0)],
            residuals_post.abs().row_sum()[(0, 0)]
        );

        let mut cams_by_name = std::collections::BTreeMap::new();

        for (name, ba_cam) in cam_names.iter().zip(ba.cams().iter()) {
            let old_cam = cal_result.cam_system.cam_by_name(name).unwrap();
            let e = ba_cam.extrinsics().clone();
            let mut i = ba_cam.intrinsics().clone();
            if undistort_prior_to_bundle_adj {
                // use original distortion
                i.distortion = old_cam.intrinsics().distortion.clone();
            }
            let cam = braid_mvg::Camera::new(old_cam.width(), old_cam.height(), e, i)?;
            cams_by_name.insert(name.clone(), cam);
        }
        let ba_system = flydra_mvg::FlydraMultiCameraSystem::new(cams_by_name, None);
        lines.push(format!(
            "Results after refinement with bundle adjustment model \"{model_type:?}\":"
        ));

        // TODO: save these values to a file alongside calibration output.
        show_points(ba.points(), &ids3d, &mut lines);
        show_points_distances(ba.points(), &points0, &ids3d, &mut lines);
        show_cams(&cam_names, ba_system.system(), &mut lines)?;
        show_reproj_matrix(
            &cam_names,
            ba_system.system(),
            &observed_per_cam,
            &tag_id_to_pt_idx,
            ba.points(),
            &mut lines,
        )?;
        ba_system
    };

    let mut xml_buf: Vec<u8> = lines.xml_comment_buf()?;
    multi_cam_system
        .to_flydra_xml(&mut xml_buf)
        .expect("to_flydra_xml");

    let mut fd = std::fs::File::create_new(&output_xml)
        .with_context(|| format!("While creating output xml file \"{output_xml}\""))?;
    fd.write_all(&xml_buf)?;
    Ok(())
}

fn show_points(points: &nalgebra::Matrix3xX<f64>, ids3d: &[u32], lines: &mut LineBuf) {
    // sort points
    let mut x = BTreeMap::new();
    for i in 0..points.ncols() {
        let id = &ids3d[i];
        let pt = points.column(i);
        x.insert(*id, pt);
    }
    lines.push(format!(" 3d point locations:"));
    lines.push(format!("     id        x       y       z"));
    for (id, pt) in x.iter() {
        lines.push(format!("  {id:>5}: {:7.3} {:7.3} {:7.3}", pt.x, pt.y, pt.z));
    }
}

fn show_points_distances(
    points1: &nalgebra::Matrix3xX<f64>,
    points0: &nalgebra::Matrix3xX<f64>,
    ids3d: &[u32],
    lines: &mut LineBuf,
) {
    assert_eq!(points1.ncols(), points0.ncols());
    assert_eq!(ids3d.len(), points1.ncols());
    // sort points
    let mut x = BTreeMap::new();
    for i in 0..points1.ncols() {
        let id = &ids3d[i];
        let pt1 = points1.column(i);
        let pt0 = points0.column(i);
        let dist = (pt1 - pt0).norm();
        x.insert(*id, dist);
    }
    lines.push(format!(
        " 3d distance between original and updated point locations:"
    ));
    lines.push(format!("     id     dist"));
    for (id, dist) in x.iter() {
        lines.push(format!("  {id:>5}: {:7.4}", dist));
    }
}

fn show_points_csv(points: &nalgebra::Matrix3xX<f64>, ids3d: &[u32], lines: &mut LineBuf) {
    lines.push(format!("id,x,y,z"));
    for i in 0..points.ncols() {
        let id = &ids3d[i];
        let pt = points.column(i);
        lines.push(format!("{id},{},{},{}", pt.x, pt.y, pt.z));
    }
}

fn show_cams(
    cam_names: &[String],
    system: &braid_mvg::MultiCameraSystem<f64>,
    lines: &mut LineBuf,
) -> eyre::Result<()> {
    lines.push(format!(
        " Camera parameters:          t_x      t_y      t_z      r_x      r_y      r_z"
    ));
    for cam_name in cam_names.iter() {
        let cam = system.cam_by_name(cam_name).unwrap();
        let cc = cam.extrinsics().camcenter();
        let (x, y, z) = (cc.x, cc.y, cc.z);
        let rot = cam.extrinsics().pose().rotation.scaled_axis();
        let (rx, ry, rz) = (rot.x, rot.y, rot.z);
        lines.push(format!(
            " {cam_name:>20}:  {x:8.3} {y:8.3} {z:8.3} {rx:8.3} {ry:8.3} {rz:8.3}"
        ));
    }
    Ok(())
}

fn show_reproj_matrix(
    cam_names: &[String],
    system: &braid_mvg::MultiCameraSystem<f64>,
    observed_per_cam: &BTreeMap<String, BTreeMap<u32, (f64, f64)>>,
    tag_id_to_pt_idx: &BTreeMap<u32, usize>,
    points: &nalgebra::Matrix3xX<f64>,
    lines: &mut LineBuf,
) -> eyre::Result<()> {
    lines.push(format!(" Reprojection distance:"));
    {
        let mut bits = vec!["      id".to_string()];
        for cam_name in cam_names.iter() {
            let last = if cam_name.len() >= 7 {
                let end = cam_name.len();
                let last = cam_name[end - 6..end].to_string();
                format!("…{last}")
            } else {
                cam_name.clone()
            };
            bits.push(format!("{last:>7}"));
        }
        bits.push(format!("{:>7}", "mean"));
        let joined = bits.join(" ");
        let space = " ".repeat((joined.len() - 6) / 2);
        lines.push(format!("{}Camera{}", space, space));
        lines.push(format!("{}", joined));
    }
    let mut dists: BTreeMap<_, Vec<_>> = Default::default();
    for (id, ipt_idx) in tag_id_to_pt_idx.iter() {
        let mut bits = vec![format!("  {id:>6}")];
        let pt3d = points.column(*ipt_idx);
        let pts = cam_geom::Points::new(pt3d.transpose());

        let mut id_dists = vec![];
        for cam_name in cam_names.iter() {
            let cam = system.cam_by_name(cam_name).unwrap();
            let pt2d_expected = cam.as_ref().world_to_pixel(&pts).data.transpose();
            if let Some(uv) = observed_per_cam.get(cam_name).unwrap().get(id) {
                let pt2d_observed = nalgebra::Vector2::new(uv.0, uv.1);
                let dist = (pt2d_observed - pt2d_expected).norm();
                dists.entry(cam_name).or_default().push(dist);
                id_dists.push(dist);
                bits.push(format!("{dist:7.2}"));
            } else {
                bits.push(format!("     - "));
            }
        }
        let mean_id = id_dists.iter().sum::<f64>() / id_dists.len() as f64;
        bits.push(format!("{mean_id:7.2}"));
        lines.push(format!("{}", bits.join(" ")));
    }
    {
        let mut bits = vec!["    mean".to_string()];
        let mut all_dist = vec![];
        for cam_name in cam_names.iter() {
            if let Some(dists) = dists.get(cam_name) {
                let mean_dist = dists.iter().sum::<f64>() / dists.len() as f64;
                bits.push(format!("{mean_dist:7.2}"));
                all_dist.extend(dists);
            } else {
                bits.push(format!("     - "));
            }
        }
        let mean_dist = all_dist.iter().sum::<f64>() / all_dist.len() as f64;
        bits.push(format!("{mean_dist:7.2}"));
        lines.push(format!("{}", bits.join(" ")));
    }
    Ok(())
}

fn to_rr_image<P: AsRef<Utf8Path>>(fname: P) -> eyre::Result<re_types::archetypes::EncodedImage> {
    let contents = std::fs::read(fname.as_ref())?;
    Ok(re_types::archetypes::EncodedImage::from_file_contents(
        contents,
    ))
}

#[cfg(test)]
mod test {
    use camino::{Utf8Path, Utf8PathBuf};
    use eyre::Result;
    use std::{
        fs,
        io::{self, Read, Seek},
    };
    use zip::ZipArchive;

    fn unpack_zip_into<R: Read + Seek>(
        mut archive: ZipArchive<R>,
        mcsc_dir_name: &Utf8Path,
    ) -> Result<()> {
        fs::create_dir_all(&mcsc_dir_name).unwrap();
        for i in 0..archive.len() {
            let mut file = archive.by_index(i).unwrap();
            let outpath = match file.enclosed_name() {
                Some(path) => Utf8PathBuf::from_path_buf(path.to_owned()).unwrap(),
                None => continue,
            };
            let outpath = mcsc_dir_name.join(outpath);

            if (*file.name()).ends_with('/') {
                fs::create_dir_all(&outpath).unwrap();
            } else {
                if let Some(p) = outpath.parent() {
                    if !p.exists() {
                        fs::create_dir_all(p).unwrap();
                    }
                }
                let mut outfile = fs::File::create(&outpath).unwrap();
                io::copy(&mut file, &mut outfile).unwrap();
            }
        }
        Ok(())
    }

    #[tracing_test::traced_test]
    #[test]
    fn test_cli() -> Result<()> {
        const FNAME: &str = "braid-april-cal-test-data.zip";
        const SHA256SUM: &str = "7f6992079af987c668ea09f86500ebadb5f76cb1a0182aa08f8788304cdba565";
        const URL_BASE: &str = "https://strawlab-cdn.com/assets/";

        download_verify::download_verify(
            format!("{}/{}", URL_BASE, FNAME).as_str(),
            FNAME,
            &download_verify::Hash::Sha256(SHA256SUM.into()),
        )
        .unwrap();

        let data_root = tempfile::tempdir()?;
        let data_root_dir_name =
            Utf8PathBuf::from_path_buf(std::path::PathBuf::from(data_root.path())).unwrap();

        let rdr = std::fs::File::open(FNAME)?;
        let cal_data_archive = ZipArchive::new(rdr)?;

        unpack_zip_into(cal_data_archive, &data_root_dir_name)?;

        let opt = super::Cli {
            apriltags_3d_fiducial_coords: data_root_dir_name
                .join("braid-april-cal-test-data/3d-fiducial-coords.csv"),
            apriltags_2d_detections_dir: data_root_dir_name.join("braid-april-cal-test-data"),
            intrinsics_yaml_dir: data_root_dir_name.join("braid-april-cal-test-data/intrinsics"),
            output_xml: data_root_dir_name.join("output.xml"),
            bundle_adjustment: true,
            ..Default::default()
        };
        super::perform_calibration(opt)?;
        // TODO: check that the calibration makes sense...
        Ok(())
    }
}
